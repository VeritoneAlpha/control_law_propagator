{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the prototype of the Mean Field\n",
    "\n",
    "There will be three main modules:\n",
    "\n",
    "- 1) Agent\n",
    "\n",
    "- 2) MeanField\n",
    "\n",
    "- 3) BlackBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import ode\n",
    "from sliding_window import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \n",
    "    def __init__(self, mean_field, blackboard, state_indices, control_indices):\n",
    "        '''\n",
    "        state_indices (list of integers): This list tells which states pertain to this agent. e.g. [1,2] would \n",
    "        tell us that states 1 and 2 pertain to this agent.\n",
    "        \n",
    "        A word on notation:  The notation used for the methods of the agent is:  \n",
    "            - If it is a partial derivative: <denominator>_rhs_H_<type of hamiltonian (l, mf, or s)>_<nou or u>.  e.g., \n",
    "            \"qp_rhs_H_l_u\" denotes the partial derivative with respect to q and p of the terms in the local Hamiltonian that contain control variables.\n",
    "            - If it is a hamiltonian: H_<type of hamiltonian (l, mf, or s)>_<nou or u>.  e.g. \"H_mf_nou\" denotes the mean field hamiltonian\n",
    "            with terms not containing u.\n",
    "        '''\n",
    "        self.state_indices = state_indices\n",
    "        self.control_indices = control_indices\n",
    "        self.mf = mean_field\n",
    "        self.bb = blackboard\n",
    "\n",
    "        # Inputs for numerical propagator\n",
    "        # qp_vec is going to be [q_s, p_l, p_mf], so it will have dimension = 3*state_dim\n",
    "\n",
    "        self.q_s_0 = np.array([0])\n",
    "        self.p_l_0 = np.array([0])\n",
    "        self.p_mf_0 = np.array([0])\n",
    "        self.u_0 = np.array([0])\n",
    "        self.qpu_vec = np.hstack([self.q_s_0, self.p_l_0, self.p_mf_0, self.u_0])\n",
    "        self.state_dim = 1\n",
    "        self.Gamma = 1 \n",
    "        self.gamma = 1\n",
    "\n",
    "        # Inputs for numerical integration\n",
    "        self.integrateTol = 10**-3\n",
    "        self.integrateMaxIter = 40\n",
    "\n",
    "        # Inputs for sliding window\n",
    "        self.t_0 = 0 \n",
    "        self.T =  2\n",
    "        self.K=1 \n",
    "\n",
    "        self.t_terminal = 2\n",
    "        self.n_s = 10\n",
    "\n",
    "        self.validate_dimensions()\n",
    "\n",
    "    def validate_dimensions(self):\n",
    "        # TODO: move to parent class \"SlidingWindow\"\n",
    "        assert len(self.state_indices) == self.state_dim, 'state dimensions are not consistent.  dimension of state indices is '+str(len(self.state_indices)) +' and state_dim is '+str(self.state_dim)\n",
    "        assert len(self.control_indices) == len(self.u_0), 'control dimensions are not consistent.  dimension of control_indices is '+str(len(self.control_indices)) +' and len(u_0) is '+str(len(self.u_0))\n",
    "        assert len(self.qpu_vec) == 3*self.state_dim + len(self.control_indices), ' control and state dimensions are not consistent with qpu_vec : length of qpu_vec is '+str(len(self.qpu_vec))+ ' and 3*self.state_dim + len(self.control_indices) is ' + str(3*self.state_dim + len(self.control_indices))\n",
    "    \n",
    "    '''\n",
    "    TODO:  \n",
    "    Add an assertion to check that the dimension of q_s_0, p_mf_0, and u_0:\n",
    "        - the dimension of state_dim    \n",
    "        - state_indices and control_indices set upon initiation of the Agent\n",
    "        - \n",
    "    '''\n",
    "    \n",
    "    def L_l(self, q, q_dot, u):\n",
    "        return\n",
    "    \n",
    "    def L_l_q_dot(self, t, q, q_dot, u, **kwargs):\n",
    "        return\n",
    "    \n",
    "    def H_l_nou(self, q, p, lambda_l):\n",
    "        return \n",
    "\n",
    "    def qp_rhs_H_l_nou(self, t, qp_vec, **kwargs):\n",
    "        dim = len(qp_vec)/2\n",
    "        q = qp_vec[:dim]\n",
    "        p = qp_vec[dim:2*dim]\n",
    "        u = kwargs['u_0']\n",
    "        # for q-dot\n",
    "        q_dot =  np.zeros(np.shape(p))\n",
    "        # for p-dot\n",
    "        p_dot =  np.zeros(np.shape(q))\n",
    "        q_D_dot = np.zeros(np.shape(p))\n",
    "        p_D_dot = np.zeros(np.shape(q))\n",
    "        return np.concatenate([q_dot, p_dot, q_D_dot, p_D_dot])\n",
    "       \n",
    "    def u_rhs_H_l_nou(self, t, u_vec, **kwargs):\n",
    "        qp_vec = kwargs['qp_vec']\n",
    "        dim = len(qp_vec)/4\n",
    "        q = qp_vec[:dim]\n",
    "        p = qp_vec[dim:2*dim]\n",
    "        q_D = qp_vec[2*dim:3*dim]\n",
    "        p_D = qp_vec[3*dim:]\n",
    "        Gamma = kwargs['Gamma']\n",
    "        # for u-dot\n",
    "        returnurn -1*Gamma*np.zeros(np.shape(u_vec))\n",
    "\n",
    "    def H_l_u(self, q, p, u):\n",
    "        return \n",
    "    \n",
    "    def qp_rhs_H_l_u(self, t, qp_vec, **kwargs):\n",
    "        dim = len(qp_vec)/4\n",
    "        q = qp_vec[:dim]\n",
    "        p = qp_vec[dim:2*dim]\n",
    "        q_D = qp_vec[2*dim:3*dim]\n",
    "        p_D = qp_vec[3*dim:]\n",
    "        u = kwargs['u_0']\n",
    "        # for q-dot\n",
    "        q_dot =  np.zeros(np.shape(p))\n",
    "        # for p-dot\n",
    "        p_dot =  np.zeros(np.shape(q))\n",
    "        q_D_dot =  np.zeros(np.shape(p))\n",
    "        p_D_dot =  np.zeros(np.shape(q))\n",
    "        return np.concatenate([q_dot, p_dot, q_D_dot, p_D_dot])\n",
    "       \n",
    "    def u_rhs_H_l_u(self, t, u_vec, **kwargs):\n",
    "        qp_vec = kwargs['qp_vec']\n",
    "        dim = len(qp_vec)/4\n",
    "        q = qp_vec[:dim]\n",
    "        p = qp_vec[dim:2*dim]\n",
    "        q_D = qp_vec[2*dim:3*dim]\n",
    "        p_D = qp_vec[3*dim:]\n",
    "        Gamma = kwargs['Gamma']\n",
    "        # for u-dot\n",
    "        return -1*Gamma*np.zeros(np.shape(u_vec))\n",
    "\n",
    "    def H_l_D(self, q_lD, p_lD):\n",
    "        return np.array(q_lD).dot(p_lD) \n",
    "        \n",
    "    def L_l_D(self, q_lD, p_lD):\n",
    "        return np.array(q_lD).dot(p_lD)\n",
    "        \n",
    "    def L_l_D_q_Dot(self, q_lD, p_lD):\n",
    "        return q_lD\n",
    "\n",
    "    def qp_rhs(self, t, qp_vec, **kwargs):\n",
    "        # u_s is constant (because of causality, remember?)\n",
    "        u_s = kwargs['u_0']\n",
    "        state_dim = kwargs['state_dim']\n",
    "        q_s = qp_vec[:state_dim]\n",
    "        p_l = qp_vec[state_dim:2*state_dim]\n",
    "        p_mf = qp_vec[2*state_dim:]\n",
    "\n",
    "        qp_rhs_H_mf = self.mf.qp_rhs_H_mf(q_s, p_mf, p_l, u_s)\n",
    "#         import pdb; pdb.set_trace()        \n",
    "        p_rhs_H_mf = qp_rhs_H_mf[:state_dim]\n",
    "        q_rhs_H_mf = qp_rhs_H_mf[state_dim:]\n",
    "        \n",
    "        qp_rhs_H_l = self.qp_rhs_H_l(q_s, p_l, u_s)\n",
    "        q_rhs_H_l = qp_rhs_H_l[:state_dim]\n",
    "        p_rhs_H_l = qp_rhs_H_l[state_dim:]\n",
    "\n",
    "        q_s_dot = self.gamma*q_rhs_H_mf + (1-self.gamma)*q_rhs_H_l\n",
    "        p_mf_dot = p_rhs_H_mf\n",
    "        p_l_dot = -1*p_rhs_H_l\n",
    "        \n",
    "        return np.concatenate([q_s_dot, p_l_dot, p_mf_dot])\n",
    "    \n",
    "    def qp_rhs_H_l(self, q_s, p_l, u_s):\n",
    "        q_rhs_H_l = self.q_rhs_H_l(q_s, p_l, u_s)\n",
    "        p_rhs_H_l = self.p_rhs_H_l(q_s, p_l, u_s)\n",
    "        return np.concatenate([q_rhs_H_l, p_rhs_H_l])\n",
    "    \n",
    "    def p_rhs_H_l(self, q_s, p_l, u_s):\n",
    "        q_s_dot =  q_s+p_l+u_s \n",
    "        return q_s_dot\n",
    "    \n",
    "    def q_rhs_H_l(self, q_s, p_l, u_s):\n",
    "        p_l_dot =  q_s + p_l + u_s\n",
    "        return p_l_dot\n",
    "\n",
    "    def u_rhs(self, t, u_vec, **kwargs):\n",
    "        return -1*self.Gamma*np.zeros(np.shape(u_vec)) \n",
    "\n",
    "    ## Mean Field methods \n",
    "    def H_MF_nou(self, q_s, p_mf, p_l, u_s):\n",
    "        return 1\n",
    "\n",
    "    def H_MF_u(self, q_s, p_mf, p_l, u_s):\n",
    "        return 1\n",
    "        \n",
    "    def qp_rhs_H_mf(self, q_s, p_mf, p_l, u_s):\n",
    "        # remember that we want to propagate as much as possible together in the same rhs function for numerical purposes\n",
    "        # remember that q_rhs here is w.r.t p_mf but p_rhs here is w.r.t q_s\n",
    "        q_H_mf_dot = self.p_rhs_H_mf(q_s, p_mf, p_l, u_s)\n",
    "        p_H_mf_dot = self.q_rhs_H_mf(q_s, p_mf, u_s)\n",
    "        return np.concatenate([q_H_mf_dot, p_H_mf_dot])\n",
    "    \n",
    "    def q_rhs_H_mf(self, q_s, p_mf, u_s):\n",
    "        p_H_mf_dot = self.q_rhs_H_mf_nou(q_s, p_mf) + sum(self.q_rhs_H_mf_u(q_s, p_mf)*u for i,j in zip())\n",
    "        return p_H_mf_dot\n",
    "        \n",
    "    def q_rhs_H_mf_u(self, q_s, p_mf):\n",
    "        # there should be one of these for each control variable\n",
    "        p_H_mf_u_dot_1 = q_s + p_mf # or something\n",
    "        return np.concatenate([p_H_mf_u_dot_1]) #, p_H_mf_u_dot_2])\n",
    "    \n",
    "    def p_rhs_H_mf(self, q_s, p_mf, p_l, u_s):\n",
    "        return self.p_rhs_H_mf_nou(q_s, p_mf) + sum([self.p_rhs_H_mf_u(q_s, p_mf)*u for i,j in zip()])\n",
    "\n",
    "    def p_rhs_H_mf_nou(self, q_s, p_mf):\n",
    "        return q_s+p_mf # or something\n",
    "\n",
    "    def q_rhs_H_mf_nou(self, q_s, p_mf):\n",
    "        p_H_mf_nou_dot_1 = q_s + p_mf\n",
    "        return np.concatenate([p_H_mf_nou_dot_1]) #, p_H_mf_nou_dot_2])\n",
    "\n",
    "    def p_rhs_H_mf_u(self, q_s, p_mf):\n",
    "        return \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Agent2:\n",
    "    \n",
    "    def __init__(self, mean_field, blackboard, state_indices, control_indices):\n",
    "        '''\n",
    "        state_indices (list of integers): This list tells which states pertain to this agent. e.g. [1,2] would \n",
    "        tell us that states 1 and 2 pertain to this agent.\n",
    "        \n",
    "        A word on notation:  The notation used for the methods of the agent is:  \n",
    "            - If it is a partial derivative: <denominator>_rhs_H_<type of hamiltonian (l, mf, or s)>_<nou or u>.  e.g., \n",
    "            \"qp_rhs_H_l_u\" denotes the partial derivative with respect to q and p of the terms in the local Hamiltonian that contain control variables.\n",
    "            - If it is a hamiltonian: H_<type of hamiltonian (l, mf, or s)>_<nou or u>.  e.g. \"H_mf_nou\" denotes the mean field hamiltonian\n",
    "            with terms not containing u.\n",
    "        '''\n",
    "        self.state_indices = state_indices\n",
    "        self.control_indices = control_indices\n",
    "        self.mf = mean_field\n",
    "        self.bb = blackboard\n",
    "\n",
    "        # Inputs for numerical propagator\n",
    "\n",
    "        self.q_s_0 = np.array([0,2])\n",
    "        self.p_l_0 = np.array([0,3])\n",
    "        self.p_mf_0 = np.array([0,1])\n",
    "        self.u_0 = np.array([0])\n",
    "        self.qpu_vec = np.hstack([self.q_s_0, self.p_l_0, self.p_mf_0, self.u_0])\n",
    "        self.state_dim = 2\n",
    "        self.Gamma = 1 \n",
    "        self.gamma = 1\n",
    "\n",
    "        # Inputs for numerical integration\n",
    "        self.integrateTol = 10**-3\n",
    "        self.integrateMaxIter = 40\n",
    "\n",
    "        # Inputs for sliding window\n",
    "        self.t_0 = 0 \n",
    "        self.T =  2\n",
    "        self.K=1 \n",
    "\n",
    "        self.t_terminal = 2\n",
    "        self.n_s = 10\n",
    "\n",
    "        self.validate_dimensions()\n",
    "\n",
    "    def validate_dimensions(self):\n",
    "        # TODO: move to parent class \"SlidingWindow\"\n",
    "        assert len(self.state_indices) == self.state_dim, 'state dimensions are not consistent.  dimension of state indices is '+str(len(self.state_indices)) +' and state_dim is '+str(self.state_dim)\n",
    "        assert len(self.control_indices) == len(self.u_0), 'control dimensions are not consistent.  dimension of control_indices is '+str(len(self.control_indices)) +' and len(u_0) is '+str(len(self.u_0))\n",
    "        assert len(self.qpu_vec) == 3*self.state_dim + len(self.control_indices), ' control and state dimensions are not consistent with qpu_vec : length of qpu_vec is '+str(len(self.qpu_vec))+ ' and 3*self.state_dim + len(self.control_indices) is ' + str(3*self.state_dim + len(self.control_indices))\n",
    "    \n",
    "    '''\n",
    "    TODO:  \n",
    "    Add an assertion to check that the dimension of q_s_0, p_mf_0, and u_0:\n",
    "        - the dimension of state_dim    \n",
    "        - state_indices and control_indices set upon initiation of the Agent\n",
    "        - \n",
    "    '''\n",
    "    \n",
    "    def L_l(self, q, q_dot, u):\n",
    "        return\n",
    "    \n",
    "    def L_l_q_dot(self, t, q, q_dot, u, **kwargs):\n",
    "        return\n",
    "    \n",
    "    def H_l_nou(self, q, p, lambda_l):\n",
    "        return \n",
    "\n",
    "    def qp_rhs_H_l_nou(self, t, qp_vec, **kwargs):\n",
    "        dim = len(qp_vec)/2\n",
    "        q = qp_vec[:dim]\n",
    "        p = qp_vec[dim:2*dim]\n",
    "        u = kwargs['u_0']\n",
    "        # for q-dot\n",
    "        q_dot =  np.zeros(np.shape(p))\n",
    "        # for p-dot\n",
    "        p_dot =  np.zeros(np.shape(q))\n",
    "        q_D_dot = np.zeros(np.shape(p))\n",
    "        p_D_dot = np.zeros(np.shape(q))\n",
    "        return np.concatenate([q_dot, p_dot, q_D_dot, p_D_dot])\n",
    "       \n",
    "    def u_rhs_H_l_nou(self, t, u_vec, **kwargs):\n",
    "        qp_vec = kwargs['qp_vec']\n",
    "        dim = len(qp_vec)/4\n",
    "        q = qp_vec[:dim]\n",
    "        p = qp_vec[dim:2*dim]\n",
    "        q_D = qp_vec[2*dim:3*dim]\n",
    "        p_D = qp_vec[3*dim:]\n",
    "        Gamma = kwargs['Gamma']\n",
    "        # for u-dot\n",
    "        returnurn -1*Gamma*np.zeros(np.shape(u_vec))\n",
    "\n",
    "    def H_l_u(self, q, p, u):\n",
    "        return \n",
    "    \n",
    "    def qp_rhs_H_l_u(self, t, qp_vec, **kwargs):\n",
    "        dim = len(qp_vec)/4\n",
    "        q = qp_vec[:dim]\n",
    "        p = qp_vec[dim:2*dim]\n",
    "        q_D = qp_vec[2*dim:3*dim]\n",
    "        p_D = qp_vec[3*dim:]\n",
    "        u = kwargs['u_0']\n",
    "        # for q-dot\n",
    "        q_dot =  np.zeros(np.shape(p))\n",
    "        # for p-dot\n",
    "        p_dot =  np.zeros(np.shape(q))\n",
    "        q_D_dot =  np.zeros(np.shape(p))\n",
    "        p_D_dot =  np.zeros(np.shape(q))\n",
    "        return np.concatenate([q_dot, p_dot, q_D_dot, p_D_dot])\n",
    "       \n",
    "    def u_rhs_H_l_u(self, t, u_vec, **kwargs):\n",
    "        qp_vec = kwargs['qp_vec']\n",
    "        dim = len(qp_vec)/4\n",
    "        q = qp_vec[:dim]\n",
    "        p = qp_vec[dim:2*dim]\n",
    "        q_D = qp_vec[2*dim:3*dim]\n",
    "        p_D = qp_vec[3*dim:]\n",
    "        Gamma = kwargs['Gamma']\n",
    "        # for u-dot\n",
    "        return -1*Gamma*np.zeros(np.shape(u_vec))\n",
    "\n",
    "    def H_l_D():\n",
    "        pass\n",
    "        \n",
    "    def L_l_D():\n",
    "        pass\n",
    "        \n",
    "    def L_l_D_q_Dot():\n",
    "        pass\n",
    "\n",
    "    def qp_rhs(self, t, qp_vec, **kwargs):\n",
    "        # u_s is constant (because of causality, remember?)\n",
    "        u_s = kwargs['u_0']\n",
    "        state_dim = kwargs['state_dim']\n",
    "        q_s = qp_vec[:state_dim]\n",
    "        p_l = qp_vec[state_dim:2*state_dim]\n",
    "        p_mf = qp_vec[2*state_dim:]\n",
    "\n",
    "        qp_rhs_H_mf = self.mf.qp_rhs_H_mf(q_s, p_mf, p_l, u_s)\n",
    "        \n",
    "        p_rhs_H_mf = qp_rhs_H_mf[:state_dim]\n",
    "        q_rhs_H_mf = qp_rhs_H_mf[state_dim:]\n",
    "        \n",
    "        qp_rhs_H_l = self.qp_rhs_H_l(q_s, p_l, u_s)\n",
    "        q_rhs_H_l = qp_rhs_H_l[:state_dim]\n",
    "        p_rhs_H_l = qp_rhs_H_l[state_dim:]\n",
    "        \n",
    "        q_s_dot = self.gamma*q_rhs_H_mf + (1-self.gamma)*q_rhs_H_l\n",
    "        p_mf_dot = p_rhs_H_mf\n",
    "        p_l_dot = -1*p_rhs_H_l\n",
    "        \n",
    "        return np.concatenate([q_s_dot, p_l_dot, p_mf_dot])\n",
    "    \n",
    "    def qp_rhs_H_l(self, q_s, p_l, u_s):\n",
    "        q_rhs_H_l = self.q_rhs_H_l(q_s, p_l, u_s)\n",
    "        p_rhs_H_l = self.p_rhs_H_l(q_s, p_l, u_s)\n",
    "        return np.concatenate([q_rhs_H_l, p_rhs_H_l])\n",
    "    \n",
    "    def p_rhs_H_l(self, q_s, p_l, u_s):\n",
    "        q_s_dot =  q_s+p_l+u_s \n",
    "        return q_s_dot\n",
    "    \n",
    "    def q_rhs_H_l(self, q_s, p_l, u_s):\n",
    "        p_l_dot =  q_s + p_l + u_s\n",
    "        return p_l_dot\n",
    "    \n",
    "    def u_rhs(self, t, u_vec, **kwargs):\n",
    "        return -1*self.Gamma*np.zeros(np.shape(u_vec)) \n",
    "\n",
    "    ## Mean Field methods \n",
    "    def H_MF_nou(self, q, p):\n",
    "        pass\n",
    "\n",
    "    def H_MF_u(self, q, p):\n",
    "        pass\n",
    "        \n",
    "    def qp_rhs_H_mf(self, q_s, p_mf, p_l, u_s):\n",
    "        # remember that we want to propagate as much as possible together in the same rhs function for numerical purposes\n",
    "        # remember that q_rhs here is w.r.t p_mf but p_rhs here is w.r.t q_s\n",
    "        q_H_mf_dot = self.p_rhs_H_mf(q_s, p_mf, p_l, u_s)\n",
    "        p_H_mf_dot = self.q_rhs_H_mf(q_s, p_mf, u_s)\n",
    "        return np.concatenate([q_H_mf_dot, p_H_mf_dot])\n",
    "    \n",
    "    def q_rhs_H_mf(self, q_s, p_mf, u_s):\n",
    "        p_H_mf_dot = self.q_rhs_H_mf_nou(q_s, p_mf) + sum(self.q_rhs_H_mf_u(q_s, p_mf)*u for i,j in zip())\n",
    "        return p_H_mf_dot\n",
    "        \n",
    "    def q_rhs_H_mf_u(self, q_s, p_mf):\n",
    "        # there should be one of these for each control variable\n",
    "        p_H_mf_u_dot_1 = q_s + p_mf # or something\n",
    "#         p_H_mf_u_dot_2 = q_s[1] + p_mf[1] # or something\n",
    "        return np.concatenate([p_H_mf_u_dot_1]) #, p_H_mf_u_dot_2])\n",
    "    \n",
    "    def p_rhs_H_mf(self, q_s, p_mf, p_l, u_s):\n",
    "        return self.p_rhs_H_mf_nou(q_s, p_mf) + sum([self.p_rhs_H_mf_u(q_s, p_mf)*u for i,j in zip()])\n",
    "\n",
    "    def p_rhs_H_mf_nou(self, q_s, p_mf):\n",
    "        return q_s+p_mf # or something\n",
    "\n",
    "    def q_rhs_H_mf_nou(self, q_s, p_mf):\n",
    "        p_H_mf_nou_dot_1 = q_s + p_mf\n",
    "        return np.concatenate([p_H_mf_nou_dot_1]) #, p_H_mf_nou_dot_2])\n",
    "\n",
    "    def p_rhs_H_mf_u():\n",
    "        pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MeanField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MeanField:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "#     def H_MF_nou(self, q, p):\n",
    "#         pass\n",
    "\n",
    "#     def H_MF_u(self, q, p):\n",
    "#         pass\n",
    "        \n",
    "#     def qp_rhs_H_mf(self, q_s, p_mf, p_l, u_s):\n",
    "#         # remember that we want to propagate as much as possible together in the same rhs function for numerical purposes\n",
    "#         # remember that q_rhs here is w.r.t p_mf but p_rhs here is w.r.t q_s\n",
    "#         q_H_mf_dot = self.p_rhs_H_mf(q_s, p_mf, p_l, u_s)\n",
    "#         p_H_mf_dot = self.q_rhs_H_mf(q_s, p_mf, u_s)\n",
    "#         return np.concatenate([q_H_mf_dot, p_H_mf_dot])\n",
    "    \n",
    "#     def q_rhs_H_mf(self, q_s, p_mf, u_s):\n",
    "#         p_H_mf_dot = self.q_rhs_H_mf_nou(q_s, p_mf) + sum(self.q_rhs_H_mf_u(q_s, p_mf)*u for i,j in zip())\n",
    "#         return p_H_mf_dot\n",
    "        \n",
    "#     def q_rhs_H_mf_u(self, q_s, p_mf):\n",
    "#         # there should be one of these for each control variable\n",
    "#         p_H_mf_u_dot_1 = q_s + p_mf # or something\n",
    "# #         p_H_mf_u_dot_2 = q_s[1] + p_mf[1] # or something\n",
    "#         return np.concatenate([p_H_mf_u_dot_1]) #, p_H_mf_u_dot_2])\n",
    "    \n",
    "#     def p_rhs_H_mf(self, q_s, p_mf, p_l, u_s):\n",
    "#         return self.p_rhs_H_mf_nou(q_s, p_mf) + sum([self.p_rhs_H_mf_u(q_s, p_mf)*u for i,j in zip()])\n",
    "\n",
    "#     def p_rhs_H_mf_nou(self, q_s, p_mf):\n",
    "#         return q_s+p_mf # or something\n",
    "\n",
    "#     def q_rhs_H_mf_nou(self, q_s, p_mf):\n",
    "#         p_H_mf_nou_dot_1 = q_s + p_mf\n",
    "#         return np.concatenate([p_H_mf_nou_dot_1]) #, p_H_mf_nou_dot_2])\n",
    "\n",
    "#     def p_rhs_H_mf_u():\n",
    "#         pass\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only 5 should be the resulting set\n"
     ]
    }
   ],
   "source": [
    "a=[3,5,2]\n",
    "b=[2]\n",
    "g=[a,b]\n",
    "set([x for g_i in g for x in g_i]) - set([3,3,3,2,4])\n",
    "print 'only 5 should be the resulting set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Synchronizer:\n",
    "    \n",
    "    def __init__(self, agents, blackboard):\n",
    "        self.agents = agents  # list of all agents.  list with elements of class Agent\n",
    "        self.bb = blackboard  # instance of class blackboard  \n",
    "    \n",
    "    def synchronize():\n",
    "        # run synchronization\n",
    "        for agent in self.agents:\n",
    "            '''     \n",
    "            1) run synchronized propagation - I think we only need one Agent instead of SlidingWindow now\n",
    "\n",
    "            For each of the above 2 steps:\n",
    "                - create sliding window instance\n",
    "                - call \"propagate_dynamics\" on the sliding window instance\n",
    "\n",
    "            get quenched values from blackboard\n",
    "            '''\n",
    "            # determine dimensions of p_l and p_MF, and then create\n",
    "            # dimensions of p_l are determined by number of states for this agent\n",
    "            # dimensions of p_MF\n",
    "            state_dim_l = len(agent.state_indices)\n",
    "            # set difference between all states in all agents, and states in current agent\n",
    "            state_dim_mf = set([agent_i.state_indices for agent_i in self.agents for agent_i.state_indices in agent_i]) - set(agent.state_indices)\n",
    "            # run propagation with keyword arguments state_dim_l, state_dim_mf\n",
    "\n",
    "            qp_vec = self.bb.construct_q_p(agent) # quench the necessary values to be quenched\n",
    "            qp_vec = qp_rhs_H_s_nou(qp_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blackboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Blackboard:\n",
    "    \n",
    "    def __init__(self):\n",
    "        '''\n",
    "#         state_agent_mapping is dictionary with keys: object of class Agent, \n",
    "#               values: list of integers state_indices state_indices\n",
    "        q_p_u_dict is a dictionary which maps 'q', 'p', 'u', to a dictionary of index-value pairs: local values for q, p, and u for this agent.  \n",
    "                        blackboard holds all of the most recent local values, e.g.\n",
    "                        {'q_s': {'1':3, '2':0}, 'p_mf': {'1':3, '2': 2}, 'u': {'1': 0}}\n",
    "                        It doesn't care which agent updated them most recently.  It only needs to know which values to update.\n",
    "        q_p_u_dict initially will be filled\n",
    "        '''\n",
    "        self.q_p_u_dict={'q_s':{}, 'p_l':{}, 'p_mf':{}, 'u_s':{}}\n",
    "        self.agents=[]\n",
    "    \n",
    "    def construct_p_q(self, agent):\n",
    "        '''\n",
    "        Inputs:\n",
    "            agent (instance of class Agent): This is the agent for which we are constructing p and q.\n",
    "        \n",
    "        Outputs:\n",
    "            q_p_u_dict (dictionary): This dictionary holds all of the q, p, and u values for ALL of the agents\n",
    "        '''\n",
    "        assert agent in self.agents, 'this agent\\'s values have not been added to the blackboard.  please call \"self.update_q_p_u_dict(<agent>)\" before calling this method'\n",
    "#         q_p_u_dict = {'q_s':{}, 'p_l':{}, 'p_mf':{}, 'u_s':{}}\n",
    "#         # find which states pertain to this agent\n",
    "#         # we cannot just return self.q_p_u_dict because the dimensions are different for different agents\n",
    "#         # for the states that don't, get the values from q_p_u_dict and put them into qp_vec\n",
    "#         print agent.state_indices\n",
    "#         for state_ix in agent.state_indices:\n",
    "#             q_p_u_dict['q_s'][str(state_ix)] = self.q_p_u_dict['q_s'][str(state_ix)]\n",
    "#             q_p_u_dict['p_l'][str(state_ix)] = self.q_p_u_dict['p_l'][str(state_ix)]\n",
    "#             q_p_u_dict['p_mf'][str(state_ix)] = self.q_p_u_dict['p_mf'][str(state_ix)]\n",
    "\n",
    "#         for control_ix in agent.control_indices:\n",
    "#             q_p_u_dict['u_s'][str(control_ix)] = self.q_p_u_dict['u_s'][str(control_ix)]\n",
    "\n",
    "#         # for state indices which are not part of agent.state_indices, fill in from blackboard q_p_u_dict\n",
    "#         assert len(set([str(x) for x in agent.control_indices]) - set(self.q_p_u_dict['u_s'].keys())) == 0, ' there should not be any controls in agent that are not in blackboard '\n",
    "#         assert len(set([str(x) for x in agent.state_indices]) - set(self.q_p_u_dict['q_s'].keys())) == 0, ' there should not be any states in agent that are not in blackboard '\n",
    "\n",
    "#         # blackboard - agent\n",
    "#         # TODO: is \"set(self.q_p_u_dict['q_s'].keys())\" the best way to find all of the state indices in existence? or should we just iterate over [agent.state_indices for agent in self.agents]\n",
    "#         quenched_state_indices = set([str(x) for x in agent.state_indices]) - set(self.q_p_u_dict['q_s'].keys())\n",
    "#         print quenched_state_indices\n",
    "#         # fill in with values from blackboard\n",
    "#         for state_ix in quenched_state_indices:\n",
    "#             q_p_u_dict['q_s'][str(state_ix)] = self.q_p_u_dict['q_s'][str(state_ix)]\n",
    "#             q_p_u_dict['p_l'][str(state_ix)] = self.q_p_u_dict['p_l'][str(state_ix)]\n",
    "#             q_p_u_dict['p_mf'][str(state_ix)] = self.q_p_u_dict['p_mf'][str(state_ix)]\n",
    "            \n",
    "        return self.q_p_u_dict\n",
    "    \n",
    "    def update_q_p_u_dict(self, agent):\n",
    "        '''  This method should be called after local propagation of each agent\n",
    "        Inputs:\n",
    "            agent (instance of class Agent): this is the agent whose values we are updating\n",
    "        Outputs:\n",
    "            No outputs.  This method just updates the attributes of the blackboard,\n",
    "            just update the dictionary, agent_q_p_u_dict.\n",
    "        '''\n",
    "        # determine which states pertain to this agent and replace the old values with new\n",
    "\n",
    "        for state_ix in agent.state_indices:\n",
    "            self.q_p_u_dict['q_s'][str(state_ix)] = agent.qpu_vec[:agent.state_dim][state_ix-1]\n",
    "            self.q_p_u_dict['p_l'][str(state_ix)] = agent.qpu_vec[agent.state_dim:2*agent.state_dim][state_ix-1]\n",
    "            self.q_p_u_dict['p_mf'][str(state_ix)] = agent.qpu_vec[2*agent.state_dim:3*agent.state_dim][state_ix-1]\n",
    "            \n",
    "        for control_ix in agent.control_indices:\n",
    "            self.q_p_u_dict['u_s'][str(control_ix)] = agent.qpu_vec[3*agent.state_dim:][control_ix-1]\n",
    "            \n",
    "        if agent not in self.agents:\n",
    "            self.agents.append(agent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small test for two agents\n",
    "\n",
    "- Add agents to blackboard and meanfield\n",
    "- Run synchronizer to visit the agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bb = Blackboard()\n",
    "mean_field = MeanField()\n",
    "\n",
    "myAgent=Agent(mean_field, bb, state_indices=[1], control_indices=[1])\n",
    "myAgent2=Agent2(mean_field, bb, state_indices=[1,2], control_indices=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bb.update_q_p_u_dict(myAgent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p_l': {'1': 0}, 'p_mf': {'1': 0}, 'q_s': {'1': 0}, 'u_s': {'1': 0}}"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb.q_p_u_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q_p_u_dict = bb.construct_p_q(myAgent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p_l': {'1': 0}, 'p_mf': {'1': 0}, 'q_s': {'1': 0}, 'u_s': {'1': 0}}"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_p_u_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try a very small test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Steps to test qp_rhs and u_rhs:\n",
    "\n",
    "- Give some arbitrary initial conditions\n",
    "- create Agent\n",
    "- create Blackboard\n",
    "- create MeanField\n",
    "- connect those three things above.\n",
    "- somehow create a sliding window instance, or at least wrangle the Agent into a Sliding Window instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# forgot to pass in 'u_s' as a keyword argument\n",
    "qpu_vec, q_ss_bar, p_ls_bar, p_mfs_bar, u_bar, q_ss, p_ls, p_mfs, us = propagate_dynamics(myAgent)\n",
    "# forgot to pass in 'u_s' as a keyword argument\n",
    "qpu_vec2, q_ss_bar2, p_ls_bar2, p_mfs_bar2, u_bar2, q_ss2, p_ls2, p_mfs2, us2 = propagate_dynamics(myAgent2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing plan:\n",
    "    - Test this on a few nonzero inputs\n",
    "    - Test this on multidimensional state\n",
    "    - Test this on multidimensional control\n",
    "    - Get this working for multiple agents\n",
    "    \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0.]),\n",
       " array([0.]),\n",
       " array([0.]),\n",
       " array([0.]),\n",
       " array([0.]),\n",
       " [array([0.])],\n",
       " [array([0.])],\n",
       " [array([0.])],\n",
       " [array([0.])])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qpu_vec, q_ss_bar, p_ls_bar, p_mfs_bar, u_bar, q_ss, p_ls, p_mfs, us"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0.        ,  82.30417415,   0.        , -27.22676579,\n",
       "          0.        ,  81.30417415,   0.        ]),\n",
       " array([ 0.        , 11.57728582]),\n",
       " array([ 0.        , -2.72097727]),\n",
       " array([ 0.        , 10.57728582]),\n",
       " array([0.]),\n",
       " [array([ 0.        , 11.57728582])],\n",
       " [array([ 0.        , -2.72097727])],\n",
       " [array([ 0.        , 10.57728582])],\n",
       " [array([0.])])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qpu_vec2, q_ss_bar2, p_ls_bar2, p_mfs_bar2, u_bar2, q_ss2, p_ls2, p_mfs2, us2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
