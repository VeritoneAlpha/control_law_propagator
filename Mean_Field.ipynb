{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the prototype of the Mean Field\n",
    "\n",
    "There will be three main modules:\n",
    "\n",
    "- 1) Agent\n",
    "\n",
    "- 2) MeanField\n",
    "\n",
    "- 3) BlackBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import ode\n",
    "from sliding_window import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \n",
    "    def __init__(self, state_indices):\n",
    "        '''\n",
    "        state_indices (list of integers): This list tells which states pertain to this agent. e.g. [1,2] would \n",
    "        tell us that states 1 and 2 pertain to this agent.\n",
    "        '''\n",
    "        self.state_indices = state_indices\n",
    "        self.control_indices = control_indices\n",
    "    \n",
    "    def L_l(self, q, q_dot, u):\n",
    "        return\n",
    "    \n",
    "    def L_l_q_dot(self, t, q, q_dot, u, **kwargs):\n",
    "        return\n",
    "    \n",
    "    def H_l_nou(self, q, p, lambda_l):\n",
    "        return \n",
    "\n",
    "    def qp_rhs_l_nou(self, t, qp_vec, **kwargs):\n",
    "        dim = len(qp_vec)/4\n",
    "        q = qp_vec[:dim]\n",
    "        p = qp_vec[dim:2*dim]\n",
    "        q_D = qp_vec[2*dim:3*dim]\n",
    "        p_D = qp_vec[3*dim:]\n",
    "        u = kwargs['u_0']\n",
    "        # for q-dot\n",
    "        q_dot =  np.zeros(np.shape(p))\n",
    "        # for p-dot\n",
    "        p_dot =  np.zeros(np.shape(q))\n",
    "        q_D_dot =  np.zeros(np.shape(p))\n",
    "        p_D_dot =  np.zeros(np.shape(q))\n",
    "        return np.concatenate([q_dot, p_dot, q_D_dot, p_D_dot])\n",
    "       \n",
    "    def u_rhs_l_nou(self, t, u_vec, **kwargs):\n",
    "        qp_vec = kwargs['qp_vec']\n",
    "        dim = len(qp_vec)/4\n",
    "        q = qp_vec[:dim]\n",
    "        p = qp_vec[dim:2*dim]\n",
    "        q_D = qp_vec[2*dim:3*dim]\n",
    "        p_D = qp_vec[3*dim:]\n",
    "        Gamma = kwargs['Gamma']\n",
    "        # for u-dot\n",
    "        return -1*Gamma*np.zeros(np.shape(u_vec))\n",
    "\n",
    "    def H_l_u(self, q, p, u):\n",
    "        return \n",
    "    \n",
    "    def qp_rhs_l_u(self, t, qp_vec, **kwargs):\n",
    "        dim = len(qp_vec)/4\n",
    "        q = qp_vec[:dim]\n",
    "        p = qp_vec[dim:2*dim]\n",
    "        q_D = qp_vec[2*dim:3*dim]\n",
    "        p_D = qp_vec[3*dim:]\n",
    "        u = kwargs['u_0']\n",
    "        # for q-dot\n",
    "        q_dot =  np.zeros(np.shape(p))\n",
    "        # for p-dot\n",
    "        p_dot =  np.zeros(np.shape(q))\n",
    "        q_D_dot =  np.zeros(np.shape(p))\n",
    "        p_D_dot =  np.zeros(np.shape(q))\n",
    "        return np.concatenate([q_dot, p_dot, q_D_dot, p_D_dot])\n",
    "       \n",
    "    def u_rhs_l_u(self, t, u_vec, **kwargs):\n",
    "        qp_vec = kwargs['qp_vec']\n",
    "        dim = len(qp_vec)/4\n",
    "        q = qp_vec[:dim]\n",
    "        p = qp_vec[dim:2*dim]\n",
    "        q_D = qp_vec[2*dim:3*dim]\n",
    "        p_D = qp_vec[3*dim:]\n",
    "        Gamma = kwargs['Gamma']\n",
    "        # for u-dot\n",
    "        return -1*Gamma*np.zeros(np.shape(u_vec))\n",
    "\n",
    "    def qp_rhs_H_s(self, t, qp_vec, **kwargs):\n",
    "        # This will include a term for qp_rhs_l and a term for qp_rhs_MF: \n",
    "        qp_vec\n",
    "        qp_rhs_H_s = (1-alpha)*qp_rhs_l(self, qp_vec)+alpha*qp_rhs_MF()\n",
    "        return np.concatenate([q_dot, p_dot, q_D_dot, p_D_dot])\n",
    "       \n",
    "    def u_rhs_H_s(self, t, u_vec, **kwargs):\n",
    "        return np.concatenate([q_dot, p_dot, q_D_dot, p_D_dot])\n",
    "        Gamma = kwargs['Gamma']\n",
    "        # for u-dot\n",
    "        return -1*Gamma*np.zeros(np.shape(u_vec))\n",
    "\n",
    "    def H_l_D():\n",
    "        pass\n",
    "        \n",
    "    def L_l_D():\n",
    "        pass\n",
    "        \n",
    "    def L_l_D_q_Dot():\n",
    "        pass\n",
    "    # Inputs for numerical propagator\n",
    "    q_0 = np.array([0])\n",
    "    p_0 = np.array([0])\n",
    "    q_D = np.array([0])\n",
    "    p_D = np.array([0])\n",
    "    u_0 = np.array([0])\n",
    "    qpu_vec = np.hstack([q_0, p_0, q_D, p_D, u_0])\n",
    "    state_dim = 1 \n",
    "    Gamma = 1 \n",
    "       \n",
    "    # Inputs for numerical integration\n",
    "    integrateTol = 10**-3\n",
    "    integrateMaxIter = 40\n",
    "       \n",
    "    # Inputs for sliding window\n",
    "    t_0 = 0 \n",
    "    T =  2\n",
    "    K=1 \n",
    "    t_terminal = 2 \n",
    "    n_s = 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MeanField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MeanField:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def H_MF_nou(self, q, p):\n",
    "        pass\n",
    "        \n",
    "    def qp_rhs_H_MF_nou(self, t, qp_vec, **kwargs):\n",
    "        pass\n",
    "\n",
    "    def H_MF_u(self, q, p):\n",
    "        pass\n",
    "        \n",
    "    def qp_rhs_H_MF_u(self, t, qp_vec, **kwargs):\n",
    "        pass\n",
    "          "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blackboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Blackboard:\n",
    "    \n",
    "    def __init__(self):\n",
    "        '''\n",
    "#         state_agent_mapping is dictionary with keys: object of class Agent, \n",
    "#               values: list of integers state_indices state_indices\n",
    "        '''\n",
    "#         self.state_agent_mapping={} \n",
    "        '''       \n",
    "        agent_q_p_u_values is dictionary with keys: object of class Agent, \n",
    "                    values (dictionary which maps 'q', 'p', 'u', to a dictionary of index-value pairs): local values for q, p, and u for this agent.  \n",
    "                        The indices for these values correspond to the indices given when the agent was initialized.  e.g.\n",
    "                        if ths agent was initialized as myAgent=Agent(state_indices=[1,2]).  This means that the \n",
    "                        states 1 and 2 pertain to myAgent.  Let's assume that control variable 1 also pertains to this \n",
    "                        agent. Then the entry in agent_q_p_u_values would look like so:\n",
    "                        {myAgent: {'q': {'1':q_1, '2':q_2}), 'p': {'1':p_1, '2': p_2}, 'u': {'1': u_1}}\n",
    "                        Obviously if there is a state that does not pertain to that agent, then it will not have an etry in the dictionary.\n",
    "        '''\n",
    "        self.agent_q_p_u_values={}\n",
    "    \n",
    "    def construct_p_q(self, agent):\n",
    "        '''\n",
    "        Inputs:\n",
    "            agent (instance of class Agent): This is the agent for which we are constructing p and q.\n",
    "        \n",
    "        Outputs:\n",
    "            qp_vec (np.array): vector of q and p values\n",
    "        '''\n",
    "        # find which states pertain to this agent\n",
    "        # for the states that don't, get the values from q_p_u_values and put them into qp_vec IN THE CORRECT LOCATION\n",
    "        qp_vec = \n",
    "        return qp_vec\n",
    "    \n",
    "    def update_agent(self, agent):\n",
    "        '''\n",
    "        Inputs:\n",
    "            agent (instance of class Agent): this is the agent whos values we are updating\n",
    "        Outputs:\n",
    "            No outputs.  This method just updates the attributes of the blackboard,\n",
    "            just update the dictionary, agent_q_p_u_values.\n",
    "        '''\n",
    "\n",
    "        self.agent_q_p_u_values[agent]['q']= agent.qp_dict['q']\n",
    "        self.agent_q_p_u_values[agent]['p']= agent.qp_dict['p']\n",
    "        self.agent_q_p_u_values[agent]['u'] = agent.u_dict['u']\n",
    "        \n",
    "    # Look at what things the Blackboard needs\n",
    "    # It at least needs a mapping that tells which states pertain to which agent\n",
    "    # It needs to keep track of all states, costates, controls for all agents so that we can plug in values when necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# now, work on construct_p_q\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What things we need in the blackboard:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
