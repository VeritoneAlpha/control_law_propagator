{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the prototype of the Mean Field\n",
    "\n",
    "There will be three main modules:\n",
    "\n",
    "- 1) Agent\n",
    "\n",
    "- 2) MeanField\n",
    "\n",
    "- 3) BlackBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import ode\n",
    "from sliding_window import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myAgent.qpu_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# print len(self.state_indices) == self.state_dim \n",
    "# print len(self.qpu_vec) == 3*self.state_dim + len(self.control_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print myAgent.q_l_0\n",
    "print myAgent.p_l_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print myAgent.p_mf_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "q_l_0 = np.array([0,1])\n",
    "p_l_0 = np.array([0,3])\n",
    "p_mf_0 = np.array([0,4])\n",
    "u_0 = np.array([0,2])\n",
    "qpu_vec = np.hstack([q_l_0, p_l_0, p_mf_0, u_0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 3, 0, 4, 0, 2])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qpu_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \n",
    "    def __init__(self, mean_field, blackboad, state_indices, control_indices):\n",
    "        '''\n",
    "        state_indices (list of integers): This list tells which states pertain to this agent. e.g. [1,2] would \n",
    "        tell us that states 1 and 2 pertain to this agent.\n",
    "        \n",
    "        A word on notation:  The notation used for the methods of the agent is:  \n",
    "            - If it is a partial derivative: <denominator>_rhs_H_<type of hamiltonian (l, mf, or s)>_<nou or u>.  e.g., \n",
    "            \"qp_rhs_H_l_u\" denotes the partial derivative with respect to q and p of the terms in the local Hamiltonian that contain control variables.\n",
    "            - If it is a hamiltonian: H_<type of hamiltonian (l, mf, or s)>_<nou or u>.  e.g. \"H_mf_nou\" denotes the mean field hamiltonian\n",
    "            with terms not containing u.\n",
    "        '''\n",
    "        self.state_indices = state_indices\n",
    "        self.control_indices = control_indices\n",
    "        self.mf = mean_field\n",
    "        self.bb = blackboard\n",
    "        self.u_l_vec = None\n",
    "        self.qp_l_vec = None\n",
    "        self.u_l_dict = None\n",
    "        self.qp_l_dict = None\n",
    "\n",
    "        # Inputs for numerical propagator\n",
    "        # qp_vec is going to be [q_l, p_l, p_mf], so it will have dimension = 3*state_dim\n",
    "\n",
    "        self.q_l_0 = np.array([0])\n",
    "        self.p_l_0 = np.array([0])\n",
    "        self.p_mf_0 = np.array([0])\n",
    "        self.u_0 = np.array([0])\n",
    "        self.qpu_vec = np.hstack([self.q_l_0, self.p_l_0, self.p_mf_0, self.u_0])\n",
    "        self.state_dim = 1\n",
    "        self.Gamma = 1 \n",
    "        self.gamma = 1\n",
    "\n",
    "        # Inputs for numerical integration\n",
    "        self.integrateTol = 10**-3\n",
    "        self.integrateMaxIter = 40\n",
    "\n",
    "        # Inputs for sliding window\n",
    "        self.t_0 = 0 \n",
    "        self.T =  2\n",
    "        self.K=1 \n",
    "\n",
    "        self.t_terminal = 2\n",
    "        self.n_s = 10\n",
    "\n",
    "        self.validate_dimensions()\n",
    "\n",
    "    def validate_dimensions(self):\n",
    "        # TODO: move to parent class \"SlidingWindow\"\n",
    "        assert len(self.state_indices) == self.state_dim, 'state dimensions are not consistent.  dimension of state indices is '+str(len(self.state_indices)) +' and state_dim is '+str(self.state_dim)\n",
    "        assert len(self.control_indices) == len(self.u_0), 'control dimensions are not consistent.  dimension of control_indices is '+str(len(self.control_indices)) +' and len(u_0) is '+str(len(self.u_0))\n",
    "        assert len(self.qpu_vec) == 3*self.state_dim + len(self.control_indices), ' control and state dimensions are not consistent with qpu_vec : length of qpu_vec is '+str(len(self.qpu_vec))+ ' and 3*self.state_dim + len(self.control_indices) is ' + str(3*self.state_dim + len(self.control_indices))\n",
    "    \n",
    "    '''\n",
    "    TODO:  \n",
    "    Add an assertion to check that the dimension of q_l_0, p_mf_0, and u_0:\n",
    "        - the dimension of state_dim    \n",
    "        - state_indices and control_indices set upon initiation of the Agent\n",
    "        - \n",
    "    '''\n",
    "    \n",
    "    def L_l(self, q, q_dot, u):\n",
    "        return\n",
    "    \n",
    "    def L_l_q_dot(self, t, q, q_dot, u, **kwargs):\n",
    "        return\n",
    "    \n",
    "    def H_l_nou(self, q, p, lambda_l):\n",
    "        return \n",
    "\n",
    "    def qp_rhs_H_l_nou(self, t, qp_vec, **kwargs):\n",
    "        dim = len(qp_vec)/2\n",
    "        q = qp_vec[:dim]\n",
    "        p = qp_vec[dim:2*dim]\n",
    "        u = kwargs['u_0']\n",
    "        # for q-dot\n",
    "        q_dot =  np.zeros(np.shape(p))\n",
    "        # for p-dot\n",
    "        p_dot =  np.zeros(np.shape(q))\n",
    "        q_D_dot = np.zeros(np.shape(p))\n",
    "        p_D_dot = np.zeros(np.shape(q))\n",
    "        return np.concatenate([q_dot, p_dot, q_D_dot, p_D_dot])\n",
    "       \n",
    "    def u_rhs_H_l_nou(self, t, u_vec, **kwargs):\n",
    "        qp_vec = kwargs['qp_vec']\n",
    "        dim = len(qp_vec)/4\n",
    "        q = qp_vec[:dim]\n",
    "        p = qp_vec[dim:2*dim]\n",
    "        q_D = qp_vec[2*dim:3*dim]\n",
    "        p_D = qp_vec[3*dim:]\n",
    "        Gamma = kwargs['Gamma']\n",
    "        # for u-dot\n",
    "        returnurn -1*Gamma*np.zeros(np.shape(u_vec))\n",
    "\n",
    "    def H_l_u(self, q, p, u):\n",
    "        return \n",
    "    \n",
    "    def qp_rhs_H_l_u(self, t, qp_vec, **kwargs):\n",
    "        dim = len(qp_vec)/4\n",
    "        q = qp_vec[:dim]\n",
    "        p = qp_vec[dim:2*dim]\n",
    "        q_D = qp_vec[2*dim:3*dim]\n",
    "        p_D = qp_vec[3*dim:]\n",
    "        u = kwargs['u_0']\n",
    "        # for q-dot\n",
    "        q_dot =  np.zeros(np.shape(p))\n",
    "        # for p-dot\n",
    "        p_dot =  np.zeros(np.shape(q))\n",
    "        q_D_dot =  np.zeros(np.shape(p))\n",
    "        p_D_dot =  np.zeros(np.shape(q))\n",
    "        return np.concatenate([q_dot, p_dot, q_D_dot, p_D_dot])\n",
    "       \n",
    "    def u_rhs_H_l_u(self, t, u_vec, **kwargs):\n",
    "        qp_vec = kwargs['qp_vec']\n",
    "        dim = len(qp_vec)/4\n",
    "        q = qp_vec[:dim]\n",
    "        p = qp_vec[dim:2*dim]\n",
    "        q_D = qp_vec[2*dim:3*dim]\n",
    "        p_D = qp_vec[3*dim:]\n",
    "        Gamma = kwargs['Gamma']\n",
    "        # for u-dot\n",
    "        return -1*Gamma*np.zeros(np.shape(u_vec))\n",
    "\n",
    "#     def qp_rhs_H_s_nou(self, t, qp_vec, **kwargs):\n",
    "#         # This will include a term for qp_rhs_l and a term for qp_rhs_MF\n",
    "#         # kwargs should have quenched values\n",
    "#         qp_vec_quenched = self.bb.construct_q_p(qp_vec, self)\n",
    "#         # yes it is really slow, but we read from blackboard every time we evaluate this\n",
    "#         qp_rhs_H_s = (1-alpha)*self.qp_rhs_H_l_nou(qp_vec) + alpha*mf.qp_rhs_H_mf_nou(qp_vec)\n",
    "#         # must return result in qp_vec format because ode rk23 will call this\n",
    "#         # qp_rhs_H_s should look like this: np.concatenate([q_dot, p_dot, q_D_dot, p_D_dot])\n",
    "#         return qp_rhs_H_s\n",
    "       \n",
    "#     def qp_rhs_H_s_u(self, t, qp_vec, **kwargs):\n",
    "#         # This will include a term for qp_rhs_l and a term for qp_rhs_MF: \n",
    "#         qp_rhs_H_s = (1-alpha)*qp_rhs_l(self, qp_vec) + alpha*qp_rhs_MF()\n",
    "#         return np.concatenate([q_dot, p_dot, q_D_dot, p_D_dot])\n",
    "       \n",
    "#     def u_rhs_H_s_nou(self, t, u_vec, **kwargs):\n",
    "#         # This will include a term for qp_rhs_l and a term for qp_rhs_MF: \n",
    "#         Gamma = kwargs['Gamma']\n",
    "#         # for u-dot\n",
    "#         return -1*Gamma*np.zeros(np.shape(u_vec))\n",
    "\n",
    "#     def u_rhs_H_s_u(self, t, u_vec, **kwargs):\n",
    "#         # This will include a term for qp_rhs_l and a term for qp_rhs_MF: \n",
    "#         return np.concatenate([q_dot, p_dot, q_D_dot, p_D_dot])\n",
    "#         Gamma = kwargs['Gamma']\n",
    "#         # for u-dot\n",
    "#         return -1*Gamma*np.zeros(np.shape(u_vec))\n",
    "\n",
    "    def H_l_D():\n",
    "        pass\n",
    "        \n",
    "    def L_l_D():\n",
    "        pass\n",
    "        \n",
    "    def L_l_D_q_Dot():\n",
    "        pass\n",
    "\n",
    "    def qp_rhs(self, t, qp_vec, **kwargs):\n",
    "        # u_l is constant (because of causality, remember?)\n",
    "        u_l = kwargs['u_0']\n",
    "        state_dim = kwargs['state_dim']\n",
    "        q_l = qp_vec[:state_dim]\n",
    "        p_l = qp_vec[state_dim:2*state_dim]\n",
    "        p_mf = qp_vec[2*state_dim:]\n",
    "\n",
    "        qp_rhs_H_mf = self.mf.qp_rhs_H_mf(q_l, p_mf, p_l, u_l)\n",
    "        \n",
    "        p_rhs_H_mf = qp_rhs_H_mf[:state_dim]\n",
    "        q_rhs_H_mf = qp_rhs_H_mf[state_dim:]\n",
    "        \n",
    "        qp_rhs_H_l = self.qp_rhs_H_l(q_l, p_l, u_l)\n",
    "        q_rhs_H_l = qp_rhs_H_l[:state_dim]\n",
    "        p_rhs_H_l = qp_rhs_H_l[state_dim:]\n",
    "        \n",
    "        q_l_dot = self.gamma*q_rhs_H_mf + (1-self.gamma)*q_rhs_H_l\n",
    "        p_mf_dot = p_rhs_H_mf\n",
    "        p_l_dot = -1*p_rhs_H_l\n",
    "        \n",
    "        return np.concatenate([q_l_dot, p_l_dot, p_mf_dot])\n",
    "    \n",
    "    def qp_rhs_H_l(self, q_l, p_l, u_l):\n",
    "        q_rhs_H_l = self.q_rhs_H_l(q_l, p_l, u_l)\n",
    "        p_rhs_H_l = self.p_rhs_H_l(q_l, p_l, u_l)\n",
    "        return [q_rhs_H_l, p_rhs_H_l]\n",
    "        \n",
    "    def p_rhs_H_l(self, q_l, p_l, u_l):\n",
    "        q_l_dot =  q_l, p_l, u_l \n",
    "        return q_l_dot\n",
    "    \n",
    "    def q_rhs_H_l(self, q_l, p_l, u_l):\n",
    "        p_l_dot =  q_l + p_l + u_l\n",
    "        return p_l_dot\n",
    "    \n",
    "    def u_rhs(self, t, u_vec, **kwargs):\n",
    "        return -1*self.Gamma*np.zeros(np.shape(u_vec)) \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blackboard = Blackboard()\n",
    "mean_field = MeanField()\n",
    "\n",
    "myAgent=Agent(mean_field, blackboard, state_indices=[1], control_indices=[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MeanField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class MeanField:\n",
    "    \n",
    "    def __init__(self):\n",
    "        pass\n",
    "    \n",
    "    def H_MF_nou(self, q, p):\n",
    "        pass\n",
    "\n",
    "    def H_MF_u(self, q, p):\n",
    "        pass\n",
    "        \n",
    "    def qp_rhs_H_mf(self, q_l, p_mf, p_l, u_l):\n",
    "        # remember that we want to propagate as much as possible together in the same rhs function for numerical purposes\n",
    "        # remember that q_rhs here is w.r.t p_mf but p_rhs here is w.r.t q_l\n",
    "        q_H_mf_dot = self.p_rhs_H_mf(q_l, p_mf, p_l, u_l)\n",
    "        p_H_mf_dot = self.q_rhs_H_mf(q_l, p_mf, u_l)\n",
    "        return np.concatenate([q_H_mf_dot, p_H_mf_dot])\n",
    "    \n",
    "    def q_rhs_H_mf(self, q_l, p_mf, u_l):\n",
    "        p_H_mf_dot = self.q_rhs_H_mf_nou(q_l, p_mf) + sum(self.q_rhs_H_mf_u(q_l, p_mf)*u for i,j in zip())\n",
    "        return p_H_mf_dot\n",
    "        \n",
    "    def q_rhs_H_mf_u(self, q_l, p_mf):\n",
    "        # there should be one ofthese for each control variable\n",
    "        p_H_mf_u_dot_1 = q_l + p_mf # or something\n",
    "#         p_H_mf_u_dot_2 = q_l[1] + p_mf[1] # or something\n",
    "        return np.concatenate([p_H_mf_u_dot_1]) #, p_H_mf_u_dot_2])\n",
    "    \n",
    "    def p_rhs_H_mf(self, q_l, p_mf, p_l, u_l):\n",
    "        return self.p_rhs_H_mf_nou(q_l, p_mf) + sum([self.p_rhs_H_mf_u(q_l, p_mf)*u for i,j in zip()])\n",
    "\n",
    "    def p_rhs_H_mf_nou(self, q_l, p_mf):\n",
    "        return q_l+p_mf # or something\n",
    "\n",
    "    def q_rhs_H_mf_nou(self, q_l, p_mf):\n",
    "        p_H_mf_nou_dot_1 = q_l + p_mf\n",
    "#         p_H_mf_nou_dot_2 = q_l[1] + p_mf[1] # this line is the problem\n",
    "        return np.concatenate([p_H_mf_nou_dot_1]) #, p_H_mf_nou_dot_2])\n",
    "\n",
    "#     def p_rhs_H_mf_nou(self, t, qp_vec, **kwargs):\n",
    "#         # first find out if this needs to be a RHS function, or if it is only called internally.\n",
    "    \n",
    "    def p_rhs_H_mf_u():\n",
    "        pass\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{2, 3, 5}"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a=[3,5,2]\n",
    "b=[2]\n",
    "g=[a,b]\n",
    "set([x for g_i in g for x in g_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Synchronizer:\n",
    "    \n",
    "    def __init__(self, agents, blackboard):\n",
    "        self.agents = agents  # list of all agents.  list with elements of class Agent\n",
    "        self.bb = blackboard  # instance of class blackboard  \n",
    "    \n",
    "    def synchronize():\n",
    "        # run synchronization\n",
    "        for agent in self.agents:\n",
    "            '''     \n",
    "            1) run synchronized propagation - I think we only need one Agent instead of SlidingWindow now\n",
    "\n",
    "            For each of the above 2 steps:\n",
    "                - create sliding window instance\n",
    "                - call \"propagate_dynamics\" on the sliding window instance\n",
    "\n",
    "            get quenched values from blackboard\n",
    "            '''\n",
    "            # determine dimensions of p_l and p_MF, and then create\n",
    "            # dimensions of p_l are determined by number of states for this agent \n",
    "            # dimensions of p_MF \n",
    "            state_dim_l = len(agent.state_indices)\n",
    "            # set difference between all states in all agents, and states in current agent\n",
    "            state_dim_mf = set([agent_i.state_indices for agent_i in self.agents for agent_i.state_indices in agent_i]) - set(agent.state_indices)\n",
    "            # run propagation with keyword arguments state_dim_l, state_dim_mf\n",
    "#             agent.sliding_window = \n",
    "            qp_vec = self.bb.construct_q_p(agent) # quench the necessary values to be quenched\n",
    "            qp_vec = qp_rhs_H_s_nou(qp_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blackboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Blackboard:\n",
    "    \n",
    "    def __init__(self):\n",
    "        '''\n",
    "#         state_agent_mapping is dictionary with keys: object of class Agent, \n",
    "#               values: list of integers state_indices state_indices\n",
    "        '''\n",
    "#         self.state_agent_mapping={}\n",
    "        '''       \n",
    "        q_p_u_dict is a dictionary which maps 'q', 'p', 'u', to a dictionary of index-value pairs: local values for q, p, and u for this agent.  \n",
    "                        blackboard holds all of the most recent local values, e.g.\n",
    "                        {'q': {'1':3, '2':0}, 'p': {'1':3, '2': 2}, 'u': {'1': 0}}\n",
    "                        It doesn't care which agent updated them most recently.  It only needs to know which values to update.\n",
    "        q_p_u_dict initially will be filled \n",
    "        '''\n",
    "        self.q_p_u_dict={'q':{}, 'p':{}, 'u':{}}\n",
    "        self.agents=[]\n",
    "    \n",
    "    def construct_p_q(self, agent):\n",
    "        '''\n",
    "        Inputs:\n",
    "            agent (instance of class Agent): This is the agent for which we are constructing p and q.\n",
    "        \n",
    "        Outputs:\n",
    "            q_p_u_dict (dictionary): This dictionary holds all of the q, p, and u values for all of the agents\n",
    "        '''\n",
    "        assert agent in self.agents, 'this agent\\'s values have not been added to the blackboard.  please call \"self.update_q_p_u_dict(<agent>)\" before calling this method'\n",
    "        q_p_u_dict = {'q':{}, 'p':{}, 'u':{}}\n",
    "        # find which states pertain to this agent\n",
    "        # for the states that don't, get the values from q_p_u_dict and put them into qp_vec\n",
    "        for state_ix in agent.state_indices:\n",
    "            q_p_u_dict['q'][str(state_ix)] = self.q_p_u_dict['q'][str(state_ix)]\n",
    "            q_p_u_dict['p'][str(state_ix)] = self.q_p_u_dict['p'][str(state_ix)]\n",
    "\n",
    "        for control_ix in agent.control_indices:\n",
    "            q_p_u_dict['u'][str(control_ix)] = self.q_p_u_dict['u'][str(control_ix)]\n",
    "\n",
    "        # for state indices which are not part of agent.state_indices, fill in from blackboard q_p_u_dict\n",
    "        assert len(set([str(x) for x in agent.control_indices]) - set(self.q_p_u_dict['u'].keys())) == 0, ' there should not be any controls in agent that are not in blackboard '\n",
    "        assert len(set([str(x) for x in agent.state_indices]) - set(self.q_p_u_dict['q'].keys())) == 0, ' there should not be any states in agent that are not in blackboard '\n",
    "\n",
    "        # blackboard - agent\n",
    "        quenched_state_indices = set([str(x) for x in agent.state_indices]) - set(self.q_p_u_dict['q'].keys())\n",
    "        # fill in with values from blackboard\n",
    "        for state_ix in quenched_state_indices:\n",
    "            q_p_u_dict['q'][str(state_ix)] = self.q_p_u_dict['q'][str(state_ix)]\n",
    "            q_p_u_dict['p'][str(state_ix)] = self.q_p_u_dict['p'][str(state_ix)]\n",
    "            \n",
    "        return q_p_u_dict\n",
    "    \n",
    "    def update_q_p_u_dict(self, agent):\n",
    "        '''  This method should be called after local propagation of each agent\n",
    "        Inputs:\n",
    "            agent (instance of class Agent): this is the agent whos values we are updating\n",
    "        Outputs:\n",
    "            No outputs.  This method just updates the attributes of the blackboard,\n",
    "            just update the dictionary, agent_q_p_u_dict.\n",
    "        '''\n",
    "        # determine which states pertain to this agent and replace the old values with new\n",
    "        # assert that the number of states is same as number of costates:\n",
    "        assert len(agent.q_p_u_dict['q']) == len(agent.q_p_u_dict['p']), 'Number of states is not same as number of costates'\n",
    "        \n",
    "        for state_ix in agent.state_indices:\n",
    "            self.q_p_u_dict['q'][str(state_ix)] = agent.q_p_u_dict['q'][str(state_ix)]\n",
    "            self.q_p_u_dict['p'][str(state_ix)] = agent.q_p_u_dict['p'][str(state_ix)]\n",
    "            \n",
    "        for control_ix in agent.control_indices:\n",
    "            self.q_p_u_dict['u'][str(control_ix)] = agent.q_p_u_dict['u'][str(control_ix)]\n",
    "        self.agents.append(agent)\n",
    "    # Look at what things the Blackboard needs\n",
    "    # It at least needs a mapping that tells which states pertain to which agent\n",
    "    # It needs to keep track of all states, costates, controls for all agents so that we can plug in values when necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### small test for one agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": " control dimensions and state are not consistent with qpu_vec : length of qpu_vec is 4 and 3*self.state_dim + len(self.control_indices) is 8",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-84-e8f6a86fe2b0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmean_field\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMeanField\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mmyAgent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_field\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mblackboard\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontrol_indices\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmyAgent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_p_u_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mmyAgent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq_p_u_dict\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'q'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-79-70d8bf150507>\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, mean_field, blackboad, state_indices, control_indices)\u001b[0m\n\u001b[1;32m     42\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_s\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidate_dimensions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mL_l\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_dot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-79-70d8bf150507>\u001b[0m in \u001b[0;36mvalidate_dimensions\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    185\u001b[0m         \u001b[0;31m# TODO: move to parent class \"SlidingWindow\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    186\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_indices\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'state dimensions are not consistent.  dimension of state indices is '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m' and state_dim is '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 187\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqpu_vec\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dim\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m' control dimensions and state are not consistent with qpu_vec : length of qpu_vec is '\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mqpu_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0;34m' and 3*self.state_dim + len(self.control_indices) is '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dim\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol_indices\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    188\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m     \u001b[0;31m# Inputs for numerical propagator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAssertionError\u001b[0m:  control dimensions and state are not consistent with qpu_vec : length of qpu_vec is 4 and 3*self.state_dim + len(self.control_indices) is 8"
     ]
    }
   ],
   "source": [
    "blackboard = Blackboard()\n",
    "mean_field = MeanField()\n",
    "\n",
    "myAgent=Agent(mean_field, blackboard, state_indices=[1,2], control_indices=[1,2])\n",
    "myAgent.q_p_u_dict={}\n",
    "myAgent.q_p_u_dict['q']={}\n",
    "myAgent.q_p_u_dict['q']['1']=0\n",
    "myAgent.q_p_u_dict['q']['2']=1\n",
    "\n",
    "myAgent.q_p_u_dict['p']={}\n",
    "myAgent.q_p_u_dict['p']['1']=0\n",
    "myAgent.q_p_u_dict['p']['2']=1\n",
    "\n",
    "myAgent.q_p_u_dict['u']={}\n",
    "myAgent.q_p_u_dict['u']['1']=0\n",
    "myAgent.q_p_u_dict['u']['2']=1\n",
    "\n",
    "bb=Blackboard()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bb.update_q_p_u_dict(myAgent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p': {'1': 0, '2': 1}, 'q': {'1': 0, '2': 1}, 'u': {'1': 0, '2': 1}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb.q_p_u_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 2]\n",
      "[1, 2]\n"
     ]
    }
   ],
   "source": [
    "print myAgent.control_indices\n",
    "print myAgent.state_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p': {'1': 0, '2': 1}, 'q': {'1': 0, '2': 1}, 'u': {'1': 0, '2': 1}}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bb.q_p_u_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q_p_u_dict = bb.construct_p_q(myAgent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p': {'1': 0, '2': 1}, 'q': {'1': 0, '2': 1}, 'u': {'1': 0, '2': 1}}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_p_u_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try a very small test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Steps to test qp_rhs and u_rhs:\n",
    "\n",
    "- Give some arbitrary initial conditions\n",
    "- create Agent\n",
    "- create Blackboard\n",
    "- create MeanField\n",
    "- connect those three things above.\n",
    "- somehow create a sliding window instance, or at least wrangle the Agent into a Sliding Window instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "blackboard = Blackboard()\n",
    "mean_field = MeanField()\n",
    "\n",
    "myAgent=Agent(mean_field, blackboard, state_indices=[1,2], control_indices=[1,2])\n",
    "myAgent.q_p_u_dict={}\n",
    "myAgent.q_p_u_dict['q'] = {}\n",
    "myAgent.q_p_u_dict['q']['1'] = 0\n",
    "myAgent.q_p_u_dict['q']['2'] = 1\n",
    "\n",
    "myAgent.q_p_u_dict['p'] = {}\n",
    "myAgent.q_p_u_dict['p']['1'] = 0\n",
    "myAgent.q_p_u_dict['p']['2'] = 1\n",
    "\n",
    "myAgent.q_p_u_dict['u']={}\n",
    "myAgent.q_p_u_dict['u']['1'] = 0\n",
    "myAgent.q_p_u_dict['u']['2'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# forgot to pass in 'u_l' as a keyword argument\n",
    "qpu_vec, q_ls_bar, p_ls_bar, p_mfs_bar, u_bar, q_ls, p_ls, p_mfs, us = propagate_dynamics(myAgent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0., 0., 0., 0.]),\n",
       " array([0.]),\n",
       " array([0.]),\n",
       " array([0.]),\n",
       " array([0.]),\n",
       " [array([0.])],\n",
       " [array([0.])],\n",
       " [array([0.])],\n",
       " [array([0.])])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qpu_vec, q_ls_bar, p_ls_bar, p_mfs_bar, u_bar, q_ls, p_ls, p_mfs, us"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing plan:\n",
    "    - Test this on a few nonzero inputs\n",
    "    - Test this on multidimensional state\n",
    "    - Test this on multidimensional control\n",
    "    - Get this working for multiple agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
