{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the prototype of the Mean Field\n",
    "\n",
    "There will be three main modules:\n",
    "\n",
    "- 1) Agent\n",
    "\n",
    "- 2) MeanField\n",
    "\n",
    "- 3) BlackBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "import ode\n",
    "from sliding_window import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \n",
    "    def __init__(self, blackboard, state_indices, control_indices):\n",
    "        '''\n",
    "        state_indices (list of integers): This list tells which states pertain to this agent. e.g. [1,2] would \n",
    "        tell us that states 1 and 2 pertain to this agent.\n",
    "        \n",
    "        A word oNn notation:  The notation used for the methods of the agent is:  \n",
    "            - If it is a partial derivative: <denominator>_rhs_H_<type of hamiltonian (l, mf, or s)>_<nou or u>.  e.g., \n",
    "            \"qp_rhs_H_l_u\" denotes the partial derivative with respect to q and p of the terms in the local Hamiltonian that contain control variables.\n",
    "            - If it is a hamiltonian: H_<type of hamiltonian (l, mf, or s)>_<nou or u>.  e.g. \"H_mf_nou\" denotes the mean field hamiltonian\n",
    "            with terms not containing u.\n",
    "        '''\n",
    "        self.state_indices = state_indices\n",
    "        self.control_indices = control_indices\n",
    "#         self.mf = mean_field\n",
    "        self.bb = blackboard\n",
    "\n",
    "        # Inputs for numerical propagator\n",
    "        # qp_vec is going to be [q_s, p_l, p_mf], so it will have dimension = 3*state_dim\n",
    "\n",
    "        self.q_s_0 = np.array([0])\n",
    "        self.p_l_0 = np.array([0])\n",
    "        self.p_mf_0 = np.array([0])\n",
    "        self.u_s_0 = np.array([0])\n",
    "        self.qpu_vec = np.hstack([self.q_s_0, self.p_l_0, self.p_mf_0, self.u_s_0])\n",
    "        self.state_dim = 1\n",
    "        self.Gamma = 1\n",
    "        self.gamma = 1\n",
    "\n",
    "        # Inputs for numerical integration\n",
    "        self.integrateTol = 10**-3\n",
    "        self.integrateMaxIter = 40\n",
    "\n",
    "        # Inputs for sliding window\n",
    "        self.t_0 = 0 \n",
    "        self.T =  2\n",
    "        self.K=1 \n",
    "\n",
    "        self.t_terminal = 4\n",
    "        self.n_s = 10\n",
    "\n",
    "        self.validate_dimensions()\n",
    "\n",
    "    def validate_dimensions(self):\n",
    "        # TODO: move to parent class \"SlidingWindow\"\n",
    "        assert len(self.state_indices) == self.state_dim, 'state dimensions are not consistent.  dimension of state indices is '+str(len(self.state_indices)) +' and state_dim is '+str(self.state_dim)\n",
    "        assert len(self.control_indices) == len(self.u_s_0), 'control dimensions are not consistent.  dimension of control_indices is '+str(len(self.control_indices)) +' and len(u_0) is '+str(len(self.u_s_0))\n",
    "        assert len(self.qpu_vec) == 3*self.state_dim + len(self.control_indices), ' control and state dimensions are not consistent with qpu_vec : length of qpu_vec is '+str(len(self.qpu_vec))+ ' and 3*self.state_dim + len(self.control_indices) is ' + str(3*self.state_dim + len(self.control_indices))\n",
    "    \n",
    "    '''\n",
    "    TODO:  \n",
    "    Add an assertion to check that the dimension of q_s_0, p_mf_0, and u_0:\n",
    "        - the dimension of state_dim    \n",
    "        - state_indices and control_indices set upon initiation of the Agent\n",
    "        - \n",
    "    '''\n",
    "    \n",
    "    def L_l(self, q_s, q_s_dot, u_s):\n",
    "        return 1\n",
    "    \n",
    "    def L_l_q_dot(self, q_s, q_s_dot, u_s):\n",
    "        return q_l\n",
    "    \n",
    "    def H_l_nou(self, q_s, p_l, lambda_l):\n",
    "        return 1\n",
    "\n",
    "    def p_rhs_H_l_nou(self, q_s, p_l, lambda_l):\n",
    "        return np.array(p_l)\n",
    "    \n",
    "    def q_rhs_H_l_nou(self, q_s, p_l, lambda_l):\n",
    "        return np.array(p_l)\n",
    "\n",
    "    def H_l_u(self, q_s, p_l):\n",
    "        return 1\n",
    "    \n",
    "    def p_rhs_H_l_u(self, q_s, p_l):\n",
    "        return np.array(p_l)\n",
    "    \n",
    "    def q_rhs_H_l_u(self, q_s, p_l):\n",
    "        return np.array(p_l)\n",
    "    \n",
    "    def H_l_D(self, q_lD, p_lD):\n",
    "        return np.array(q_lD).dot(p_lD)\n",
    "        \n",
    "    def L_l_D(self, q_lD, p_lD):\n",
    "        # return scalar\n",
    "        return 1\n",
    "        \n",
    "    def L_l_D_q_Dot(self, q_lD, p_lD):\n",
    "        # return 1 by state_dim, 1-D array\n",
    "        # each q_lD is a 1-D array of size 1 by state_dim array\n",
    "        return q_lD\n",
    "\n",
    "    def qp_rhs(self, t, qp_vec, **kwargs):\n",
    "        # u_s is constant (because of causality, remember?)\n",
    "        u_s = kwargs['u_0']\n",
    "        state_dim = kwargs['state_dim']\n",
    "        # TODO:  get a kwargs working for lambda_l\n",
    "        lambda_l = 0 #kwargs['lambda_l']\n",
    "        q_s = qp_vec[:state_dim]\n",
    "        p_l = qp_vec[state_dim:2*state_dim]\n",
    "        p_mf = qp_vec[2*state_dim:]\n",
    "\n",
    "        qp_rhs_H_mf = self.qp_rhs_H_mf(q_s, p_mf, u_s)\n",
    "        p_rhs_H_mf = qp_rhs_H_mf[:state_dim]\n",
    "        q_rhs_H_mf = qp_rhs_H_mf[state_dim:]\n",
    "        \n",
    "        qp_rhs_H_l = self.qp_rhs_H_l(q_s, p_l, u_s, lambda_l)\n",
    "        q_rhs_H_l = qp_rhs_H_l[:state_dim]\n",
    "        p_rhs_H_l = qp_rhs_H_l[state_dim:]\n",
    "\n",
    "        q_s_dot = self.gamma*q_rhs_H_mf + (1-self.gamma)*q_rhs_H_l\n",
    "        p_mf_dot = p_rhs_H_mf\n",
    "        p_l_dot = -1*p_rhs_H_l\n",
    "        \n",
    "        return np.concatenate([q_s_dot, p_l_dot, p_mf_dot])\n",
    "    \n",
    "    def qp_rhs_H_l(self, q_s, p_l, u_s, lambda_l):\n",
    "        #TODO: there is one lambda_l per constraint. need to work out dimensions.\n",
    "        q_rhs_H_l = self.q_rhs_H_l_nou(q_s, p_l, lambda_l) + sum([self.q_rhs_H_l_u(q_s, p_l)*u_s_i for u_s_i in u_s])\n",
    "        p_rhs_H_l = self.p_rhs_H_l_nou(q_s, p_l, lambda_l) + sum([self.p_rhs_H_l_u(q_s, p_l)*u_s_i for u_s_i in u_s])\n",
    "        return np.concatenate([q_rhs_H_l, p_rhs_H_l])\n",
    "\n",
    "    def u_rhs(self, t, u_vec, **kwargs):\n",
    "        return -1*self.Gamma*np.zeros(np.shape(u_vec))\n",
    "\n",
    "    ## Mean Field methods\n",
    "    def H_MF_nou(self, q_s, p_mf):\n",
    "        return 1\n",
    "\n",
    "    def H_MF_u(self, q_s, p_mf, u_s):\n",
    "        return 1\n",
    "        \n",
    "    def qp_rhs_H_mf(self, q_s, p_mf, u_s):\n",
    "        # remember that we want to propagate as much as possible together in the same rhs function for numerical purposes\n",
    "        # remember that q_rhs here is w.r.t p_mf but p_rhs here is w.r.t q_s\n",
    "        q_H_mf_dot = self.p_rhs_H_mf(q_s, p_mf, u_s)\n",
    "        p_H_mf_dot = self.q_rhs_H_mf(q_s, p_mf, u_s)\n",
    "        return np.concatenate([q_H_mf_dot, p_H_mf_dot])\n",
    "    \n",
    "    def q_rhs_H_mf(self, q_s, p_mf, u_s):\n",
    "        return self.q_rhs_H_mf_nou(q_s, p_mf) + sum([self.q_rhs_H_mf_u(q_s, p_mf)*u_i for u_i in u_s])\n",
    "        \n",
    "    def q_rhs_H_mf_u(self, q_s, p_mf):\n",
    "        # there should be one of these for each control variable\n",
    "        p_H_mf_u_dot_1 = q_s + p_mf # or something\n",
    "        return np.concatenate([p_H_mf_u_dot_1])\n",
    "    \n",
    "    def p_rhs_H_mf(self, q_s, p_mf, u_s):\n",
    "        return self.p_rhs_H_mf_nou(q_s, p_mf) + sum([self.p_rhs_H_mf_u(q_s, p_mf)*u_i for u_i in u_s])\n",
    "\n",
    "    def p_rhs_H_mf_nou(self, q_s, p_mf):\n",
    "        return q_s + p_mf # or something\n",
    "\n",
    "    def q_rhs_H_mf_nou(self, q_s, p_mf):\n",
    "        return  q_s + p_mf\n",
    "\n",
    "    def p_rhs_H_mf_u(self, q_s, p_mf):\n",
    "        q_H_mf_u_dot = q_s + p_mf\n",
    "        return np.concatenate([q_H_mf_u_dot])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Agent2:\n",
    "    \n",
    "    def __init__(self, blackboard, state_indices, control_indices):\n",
    "        '''\n",
    "        state_indices (list of integers): This list tells which states pertain to this agent. e.g. [1,2] would \n",
    "        tell us that states 1 and 2 pertain to this agent.\n",
    "        \n",
    "        A word oNn notation:  The notation used for the methods of the agent is:  \n",
    "            - If it is a partial derivative: <denominator>_rhs_H_<type of hamiltonian (l, mf, or s)>_<nou or u>.  e.g., \n",
    "            \"qp_rhs_H_l_u\" denotes the partial derivative with respect to q and p of the terms in the local Hamiltonian that contain control variables.\n",
    "            - If it is a hamiltonian: H_<type of hamiltonian (l, mf, or s)>_<nou or u>.  e.g. \"H_mf_nou\" denotes the mean field hamiltonian\n",
    "            with terms not containing u.\n",
    "        '''\n",
    "        self.state_indices = state_indices\n",
    "        self.control_indices = control_indices\n",
    "        self.bb = blackboard\n",
    "\n",
    "        # Inputs for numerical propagator\n",
    "        # qp_vec is going to be [q_s, p_l, p_mf], so it will have dimension = 3*state_dim\n",
    "\n",
    "        self.q_s_0 = np.array([0,2])\n",
    "        self.p_l_0 = np.array([0,3])\n",
    "        self.p_mf_0 = np.array([0,1])\n",
    "        self.u_s_0 = np.array([0])\n",
    "        self.qpu_vec = np.hstack([self.q_s_0, self.p_l_0, self.p_mf_0, self.u_s_0])\n",
    "        self.state_dim = 2\n",
    "        self.Gamma = 1 \n",
    "        self.gamma = 1\n",
    "\n",
    "        # Inputs for numerical integration\n",
    "        self.integrateTol = 10**-3\n",
    "        self.integrateMaxIter = 40\n",
    "\n",
    "        # Inputs for sliding window\n",
    "        self.t_0 = 0 \n",
    "        self.T = 2\n",
    "        self.K = 1 \n",
    "\n",
    "        self.t_terminal = 2\n",
    "        self.n_s = 10\n",
    "\n",
    "        self.validate_dimensions()\n",
    "\n",
    "    def validate_dimensions(self):\n",
    "        # TODO: move to parent class \"SlidingWindow\"\n",
    "        assert len(self.state_indices) == self.state_dim, 'state dimensions are not consistent.  dimension of state indices is '+str(len(self.state_indices)) +' and state_dim is '+str(self.state_dim)\n",
    "        assert len(self.control_indices) == len(self.u_s_0), 'control dimensions are not consistent.  dimension of control_indices is '+str(len(self.control_indices)) +' and len(u_0) is '+str(len(self.u_s_0))\n",
    "        assert len(self.qpu_vec) == 3*self.state_dim + len(self.control_indices), ' control and state dimensions are not consistent with qpu_vec : length of qpu_vec is '+str(len(self.qpu_vec))+ ' and 3*self.state_dim + len(self.control_indices) is ' + str(3*self.state_dim + len(self.control_indices))\n",
    "    \n",
    "    '''\n",
    "    TODO:  \n",
    "    Add an assertion to check that the dimension of q_s_0, p_mf_0, and u_0:\n",
    "        - the dimension of state_dim    \n",
    "        - state_indices and control_indices set upon initiation of the Agent\n",
    "        - \n",
    "    '''\n",
    "    \n",
    "    def L_l(self, q_s, q_s_dot, u_s):\n",
    "        return 1\n",
    "    \n",
    "    def L_l_q_dot(self, q_s, q_s_dot, u_s):\n",
    "        return q_l\n",
    "    \n",
    "    def H_l_nou(self, q_s, p_l, lambda_l):\n",
    "        return 1\n",
    "\n",
    "    def p_rhs_H_l_nou(self, q_s, p_l, lambda_l):\n",
    "        return np.array(p_l)\n",
    "    \n",
    "    def q_rhs_H_l_nou(self, q_s, p_l, lambda_l):\n",
    "        return np.array(p_l)\n",
    "\n",
    "    def H_l_u(self, q_s, p_l):\n",
    "        return 1\n",
    "    \n",
    "    def p_rhs_H_l_u(self, q_s, p_l):\n",
    "        return np.array(p_l)\n",
    "    \n",
    "    def q_rhs_H_l_u(self, q_s, p_l):\n",
    "        return np.array(p_l)\n",
    "    \n",
    "    def H_l_D(self, q_lD, p_lD):\n",
    "        return np.array(q_lD).dot(p_lD)\n",
    "        \n",
    "    def L_l_D(self, q_lD, p_lD):\n",
    "        # return scalar\n",
    "        return 1\n",
    "        \n",
    "    def L_l_D_q_Dot(self, q_lD, p_lD):\n",
    "        # return 1 by state_dim, 1-D array\n",
    "        # each q_lD is a 1-D array of size 1 by state_dim array\n",
    "        return q_lD\n",
    "\n",
    "    def qp_rhs(self, t, qp_vec, **kwargs):\n",
    "        # u_s is constant (because of causality, remember?)\n",
    "        u_s = kwargs['u_0']\n",
    "        state_dim = kwargs['state_dim']\n",
    "        # TODO:  get a kwargs working for lambda_l\n",
    "        lambda_l = 0 #kwargs['lambda_l']\n",
    "        q_s = qp_vec[:state_dim]\n",
    "        p_l = qp_vec[state_dim:2*state_dim]\n",
    "        p_mf = qp_vec[2*state_dim:]\n",
    "\n",
    "        qp_rhs_H_mf = self.qp_rhs_H_mf(q_s, p_mf, u_s)\n",
    "        p_rhs_H_mf = qp_rhs_H_mf[:state_dim]\n",
    "        q_rhs_H_mf = qp_rhs_H_mf[state_dim:]\n",
    "        \n",
    "        qp_rhs_H_l = self.qp_rhs_H_l(q_s, p_l, u_s, lambda_l)\n",
    "        q_rhs_H_l = qp_rhs_H_l[:state_dim]\n",
    "        p_rhs_H_l = qp_rhs_H_l[state_dim:]\n",
    "\n",
    "        q_s_dot = self.gamma*q_rhs_H_mf + (1-self.gamma)*q_rhs_H_l\n",
    "        p_mf_dot = p_rhs_H_mf\n",
    "        p_l_dot = -1*p_rhs_H_l\n",
    "        \n",
    "        return np.concatenate([q_s_dot, p_l_dot, p_mf_dot])\n",
    "    \n",
    "    def qp_rhs_H_l(self, q_s, p_l, u_s, lambda_l):\n",
    "        #TODO: there is one lambda_l per constraint. need to work out dimensions.\n",
    "        q_rhs_H_l = self.q_rhs_H_l_nou(q_s, p_l, lambda_l) + sum([self.q_rhs_H_l_u(q_s, p_l)*u_s_i for u_s_i in u_s])\n",
    "        p_rhs_H_l = self.p_rhs_H_l_nou(q_s, p_l, lambda_l) + sum([self.p_rhs_H_l_u(q_s, p_l)*u_s_i for u_s_i in u_s])\n",
    "        return np.concatenate([q_rhs_H_l, p_rhs_H_l])\n",
    "\n",
    "    def u_rhs(self, t, u_vec, **kwargs):\n",
    "        return -1*self.Gamma*np.zeros(np.shape(u_vec))\n",
    "\n",
    "    ## Mean Field methods\n",
    "    def H_MF_nou(self, q_s, p_mf):\n",
    "        return 1\n",
    "\n",
    "    def H_MF_u(self, q_s, p_mf, u_s):\n",
    "        return 1\n",
    "        \n",
    "    def qp_rhs_H_mf(self, q_s, p_mf, u_s):\n",
    "        # remember that we want to propagate as much as possible together in the same rhs function for numerical purposes\n",
    "        # remember that q_rhs here is w.r.t p_mf but p_rhs here is w.r.t q_s\n",
    "        q_H_mf_dot = self.p_rhs_H_mf(q_s, p_mf, u_s)\n",
    "        p_H_mf_dot = self.q_rhs_H_mf(q_s, p_mf, u_s)\n",
    "        return np.concatenate([q_H_mf_dot, p_H_mf_dot])\n",
    "    \n",
    "    def q_rhs_H_mf(self, q_s, p_mf, u_s):\n",
    "        return self.q_rhs_H_mf_nou(q_s, p_mf) + sum([self.q_rhs_H_mf_u(q_s, p_mf)*u_i for u_i in u_s])\n",
    "        \n",
    "    def q_rhs_H_mf_u(self, q_s, p_mf):\n",
    "        # there should be one of these for each control variable\n",
    "        p_H_mf_u_dot_1 = q_s + p_mf # or something\n",
    "        return np.concatenate([p_H_mf_u_dot_1])\n",
    "    \n",
    "    def p_rhs_H_mf(self, q_s, p_mf, u_s):\n",
    "        return self.p_rhs_H_mf_nou(q_s, p_mf) + sum([self.p_rhs_H_mf_u(q_s, p_mf)*u_i for u_i in u_s])\n",
    "\n",
    "    def p_rhs_H_mf_nou(self, q_s, p_mf):\n",
    "        return q_s + p_mf # or something\n",
    "\n",
    "    def q_rhs_H_mf_nou(self, q_s, p_mf):\n",
    "        return  q_s + p_mf\n",
    "\n",
    "    def p_rhs_H_mf_u(self, q_s, p_mf):\n",
    "        q_H_mf_u_dot = q_s + p_mf\n",
    "        return np.concatenate([q_H_mf_u_dot])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only 5 should be the resulting set\n"
     ]
    }
   ],
   "source": [
    "a=[3,5,2]\n",
    "b=[2]\n",
    "g=[a,b]\n",
    "set([x for g_i in g for x in g_i]) - set([3,3,3,2,4])\n",
    "print 'only 5 should be the resulting set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Synchronizer:\n",
    "    \n",
    "    def __init__(self, agents, blackboard):\n",
    "        self.agents = agents  # list of all agents.  list with elements of class Agent\n",
    "        self.bb = blackboard  # instance of class blackboard  \n",
    "    \n",
    "    def synchronize():\n",
    "        # run synchronization\n",
    "        for agent in self.agents:\n",
    "            '''     \n",
    "            1) run synchronized propagation - I think we only need one Agent instead of SlidingWindow now\n",
    "\n",
    "            For each of the above 2 steps:\n",
    "                - create sliding window instance\n",
    "                - call \"propagate_dynamics\" on the sliding window instance\n",
    "\n",
    "            get quenched values from blackboard\n",
    "            '''\n",
    "            # determine dimensions of p_l and p_MF, and then create\n",
    "            # dimensions of p_l are determined by number of states for this agent\n",
    "            # dimensions of p_MF\n",
    "            state_dim_l = len(agent.state_indices)\n",
    "            # set difference between all states in all agents, and states in current agent\n",
    "            state_dim_mf = set([agent_i.state_indices for agent_i in self.agents for agent_i.state_indices in agent_i]) - set(agent.state_indices)\n",
    "            # run propagation with keyword arguments state_dim_l, state_dim_mf\n",
    "\n",
    "            qp_vec = self.bb.construct_q_p(agent) # quench the necessary values to be quenched\n",
    "            qp_vec = qp_rhs_H_s_nou(qp_vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blackboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Blackboard:\n",
    "    \n",
    "    def __init__(self):\n",
    "        '''\n",
    "#         state_agent_mapping is dictionary with keys: object of class Agent, \n",
    "#               values: list of integers state_indices state_indices\n",
    "        q_p_u_dict is a dictionary which maps 'q', 'p', 'u', to a dictionary of index-value pairs: local values for q, p, and u for this agent.  \n",
    "                        blackboard holds all of the most recent local values, e.g.\n",
    "                        {'q_s': {'1':3, '2':0}, 'p_mf': {'1':3, '2': 2}, 'u': {'1': 0}}\n",
    "                        It doesn't care which agent updated them most recently.  It only needs to know which values to update.\n",
    "        q_p_u_dict initially will be filled\n",
    "        '''\n",
    "        self.q_p_u_dict={'q_s':{}, 'p_l':{}, 'p_mf':{}, 'u_s':{}}\n",
    "        self.agents=[]\n",
    "        \n",
    "    def update_q_p_u_dict(self, agent):\n",
    "        '''  This method should be called after local propagation of each agent\n",
    "        Inputs:\n",
    "            agent (instance of class Agent): this is the agent whose values we are updating\n",
    "        Outputs:\n",
    "            No outputs.  This method just updates the attributes of the blackboard,\n",
    "            just update the dictionary, agent_q_p_u_dict.\n",
    "        '''\n",
    "        # determine which states pertain to this agent and replace the old values with new\n",
    "\n",
    "        for state_ix in agent.state_indices:\n",
    "            self.q_p_u_dict['q_s'][str(state_ix)] = agent.qpu_vec[:agent.state_dim][state_ix-1]\n",
    "            self.q_p_u_dict['p_l'][str(state_ix)] = agent.qpu_vec[agent.state_dim:2*agent.state_dim][state_ix-1]\n",
    "            self.q_p_u_dict['p_mf'][str(state_ix)] = agent.qpu_vec[2*agent.state_dim:3*agent.state_dim][state_ix-1]\n",
    "            \n",
    "        for control_ix in agent.control_indices:\n",
    "            self.q_p_u_dict['u_s'][str(control_ix)] = agent.qpu_vec[3*agent.state_dim:][control_ix-1]\n",
    "            \n",
    "        if agent not in self.agents:\n",
    "            self.agents.append(agent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small test for two agents\n",
    "\n",
    "- Add agents to blackboard and meanfield\n",
    "- Run synchronizer to visit the agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bb = Blackboard()\n",
    "# mean_field = MeanField()\n",
    "\n",
    "myAgent=Agent(bb, state_indices=[1], control_indices=[1])\n",
    "myAgent2=Agent2(bb, state_indices=[1,2], control_indices=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bb.update_q_p_u_dict(myAgent)\n",
    "bb.update_q_p_u_dict(myAgent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q_p_u_dict = bb.q_p_u_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p_l': {'1': 0, '2': 3},\n",
       " 'p_mf': {'1': 0, '2': 1},\n",
       " 'q_s': {'1': 0, '2': 2},\n",
       " 'u_s': {'1': 0}}"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_p_u_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try a very small test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Steps to test qp_rhs and u_rhs:\n",
    "\n",
    "- Give some arbitrary initial conditions\n",
    "- create Agent\n",
    "- create Blackboard\n",
    "- create MeanField\n",
    "- connect those three things above.\n",
    "- somehow create a sliding window instance, or at least wrangle the Agent into a Sliding Window instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# forgot to pass in 'u_s' as a keyword argument\n",
    "qpu_vec, q_ss_bar, p_ls_bar, p_mfs_bar, u_bar, q_ss, p_ls, p_mfs, us = propagate_dynamics(myAgent)\n",
    "# forgot to pass in 'u_s' as a keyword argument\n",
    "qpu_vec2, q_ss_bar2, p_ls_bar2, p_mfs_bar2, u_bar2, q_ss2, p_ls2, p_mfs2, us2 = propagate_dynamics(myAgent2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing plan:\n",
    "    - Test this on a few nonzero inputs\n",
    "    - Test this on multidimensional state\n",
    "    - Test this on multidimensional control\n",
    "    - Get this working for multiple agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0.] [0.] [0.] [0.] [0.] [array([0.])] [array([0.])] [array([0.])] [array([0.])]\n"
     ]
    }
   ],
   "source": [
    "print qpu_vec, q_ss_bar, p_ls_bar, p_mfs_bar, u_bar, q_ss, p_ls, p_mfs, us\n",
    "# print qpu_vec2, q_ss_bar2, p_ls_bar2, p_mfs_bar2, u_bar2, q_ss2, p_ls2, p_mfs2, us2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try another very small test\n",
    "\n",
    "- run propagation for Agent using multiple windows so we can test using initial values, etc.\n",
    "- and we can also test all of the methods for the agent rather than only the one for \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get sliding window working for multiple windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sliding_window(sliding_window_instance):\n",
    "    ''' \n",
    "    Inputs:\n",
    "        t_0 (int): Initial time to start propagating dynamics\n",
    "        T (int): End time of propagating dynamics\n",
    "        q_0 (np.array): initial values of state vector\n",
    "        p_0 (np.array): initial values of costate vector\n",
    "        u_0 (np.array): initial values of control vector\n",
    "        state_dim (int): number of states\n",
    "        Gamma (float): algorithmic parameter for Riemann descent algorithm\n",
    "        t_terminal (int): time marking termination of control law propagator algorithm\n",
    "    Outputs:\n",
    "        q_bars, p_bars, u_bars (list of np.arrays): implemented state/costate/control values for entire propagator.\n",
    "    '''\n",
    "    t_0, T, K, q_0, p_0, u_0, state_dim, Gamma, t_terminal = sliding_window_instance.t_0, sliding_window_instance.T, sliding_window_instance.K, sliding_window_instance.q_0, sliding_window_instance.p_0, sliding_window_instance.u_0, sliding_window_instance.state_dim, sliding_window_instance.Gamma, sliding_window_instance.t_terminal\n",
    "    q_ls_bars, p_ls_bars, p_mfs_bars, u_bars = [], [], [], []\n",
    "    t = t_0 # wall clock time\n",
    "    qpu_vec = np.hstack([q_0, p_0, u_0])\n",
    "    while t < t_terminal:\n",
    "        # get values from blackboard\n",
    "        # get values from sensors\n",
    "        # set initial conditions using those two things above\n",
    "        p_0\n",
    "        # for the times, propagate_dynamics needs: t_0, T, and K.  T and K can come from the sliding_window_instance\n",
    "        #...t_0 will be passed in.  t_0 is the start of the window\n",
    "        qpu_vec, q_ls_bar, p_ls_bar, p_mfs_bar, u_bar, q_ls, p_ls, p_mfs, us = propagate_dynamics(qpu_vec, sliding_window_instance)\n",
    "        # qs, ps, and us will go to Mean Field somehow\n",
    "\n",
    "        q_ls_bars.append(q_ls_bar)\n",
    "        p_ls_bars.append(p_ls_bar)\n",
    "        p_mfs_bars.append(p_mfs_bar)\n",
    "        u_bars.append(u_bar)\n",
    "        \n",
    "    return q_ls_bars, p_ls_bars, p_mfs_bars, u_bars\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
