{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the prototype of the Mean Field\n",
    "\n",
    "There will be three main modules:\n",
    "\n",
    "- 1) Agent\n",
    "\n",
    "- 2) MeanField\n",
    "\n",
    "- 3) BlackBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import ode\n",
    "from sliding_window import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \n",
    "    def __init__(self, blackboard, state_indices, control_indices):\n",
    "        '''\n",
    "        state_indices (list of integers): This list tells which states pertain to this agent. e.g. [1,2] would \n",
    "        tell us that states 1 and 2 pertain to this agent.\n",
    "        \n",
    "        A word on notation:  The notation used for the methods of the agent is:  \n",
    "            - If it is a partial derivative: <denominator>_rhs_H_<type of hamiltonian (l, mf, or s)>_<nou or u>.  e.g., \n",
    "            \"qp_rhs_H_l_u\" denotes the partial derivative with respect to q and p of the terms in the local Hamiltonian that contain control variables.\n",
    "            - If it is a hamiltonian: H_<type of hamiltonian (l, mf, or s)>_<nou or u>.  e.g. \"H_mf_nou\" denotes the mean field hamiltonian\n",
    "            with terms not containing u.\n",
    "        '''\n",
    "        self.state_indices = state_indices\n",
    "        self.control_indices = control_indices\n",
    "        self.bb = blackboard\n",
    "\n",
    "        # Inputs for numerical propagator\n",
    "        # qp_vec is going to be [q_s, p_l, p_mf], so it will have dimension = 3*state_dim\n",
    "\n",
    "        self.q_s_0 = np.array([0])\n",
    "        self.p_l_0 = np.array([0])\n",
    "        self.p_mf_0 = np.array([0])\n",
    "        self.u_s_0 = np.array([0])\n",
    "        self.qpu_vec = np.hstack([self.q_s_0, self.p_l_0, self.p_mf_0, self.u_s_0])\n",
    "        self.q_s_dot = np.array([0])  # must have same dimensions as q_s\n",
    "        self.state_dim = 1\n",
    "        self.Gamma = 1\n",
    "        self.gamma = 1  # function is inputted by the user to compute this.\n",
    "        self.sync = None # gets filled in when Synchronizer class is initialized\n",
    "        self.name='Agent1'\n",
    "\n",
    "        # Inputs for numerical integration\n",
    "        self.integrateTol = 10**-5\n",
    "        self.integrateMaxIter = 400\n",
    "\n",
    "        # Inputs for sliding window\n",
    "        self.t_0 = 0 \n",
    "        self.T =  2\n",
    "        self.K=10\n",
    "\n",
    "        self.t_terminal = 4\n",
    "        self.n_s = 10\n",
    "\n",
    "        self.validate_dimensions()\n",
    "        \n",
    "    def compute_gamma(self):\n",
    "        # if only one agent, then gamma = 1\n",
    "        if len(self.bb.agents) == 1:\n",
    "            return 1\n",
    "        q_s, p_l, p_mf, u_s = self.qpu_vec\n",
    "        q_s_dot = self.q_s_dot\n",
    "        num = self.L_l(q_s, q_s_dot, u_s)\n",
    "        denom = 0\n",
    "\n",
    "        assert len(self.bb.agents) != 0, 'Add agents to your blackboard by calling bb.update_q_p_u_dict(<agent>)'\n",
    "        for agent in self.bb.agents:\n",
    "            denom += agent.L_l(q_s, q_s_dot, u_s)\n",
    "        self.gamma = float(num)/float(denom)\n",
    "        \n",
    "\n",
    "    def validate_dimensions(self):\n",
    "        # TODO: move to parent class \"SlidingWindow\"\n",
    "        assert len(self.state_indices) == self.state_dim, 'state dimensions are not consistent.  dimension of state indices is '+str(len(self.state_indices)) +' and state_dim is '+str(self.state_dim)\n",
    "        assert len(self.control_indices) == len(self.u_s_0), 'control dimensions are not consistent.  dimension of control_indices is '+str(len(self.control_indices)) +' and len(u_0) is '+str(len(self.u_s_0))\n",
    "        assert len(self.qpu_vec) == 3*self.state_dim + len(self.control_indices), ' control and state dimensions are not consistent with qpu_vec : length of qpu_vec is '+str(len(self.qpu_vec))+ ' and 3*self.state_dim + len(self.control_indices) is ' + str(3*self.state_dim + len(self.control_indices))\n",
    "    \n",
    "    '''\n",
    "    TODO:  \n",
    "    Add an assertion to check that the dimension of q_s_0, p_mf_0, and u_0:\n",
    "        - the dimension of state_dim\n",
    "        - state_indices and control_indices set upon initiation of the Agent\n",
    "    '''\n",
    "    \n",
    "    def L_l(self, q_s, q_s_dot, u_s):\n",
    "        return 1\n",
    "    \n",
    "    def L_l_q_dot(self, q_s, q_s_dot, u_s):\n",
    "        return q_s\n",
    "    \n",
    "    def H_l_nou(self, q_s, p_l, lambda_l):\n",
    "        return 1\n",
    "\n",
    "    def p_rhs_H_l_nou(self, q_s, p_l, lambda_l):\n",
    "        return np.array(p_l)\n",
    "    \n",
    "    def q_rhs_H_l_nou(self, q_s, p_l, lambda_l):\n",
    "        return np.array(p_l)\n",
    "    \n",
    "    # There should be one of these defined for each control variable\n",
    "\n",
    "    def H_l_u_1(self, q_s, p_s):\n",
    "        return 1\n",
    "    \n",
    "    def H_l(self, q_s, p_l, lambda_l, u_s):\n",
    "        # used in \"Construct local Hamiltonian of agent i\"\n",
    "        H_l = self.H_l_nou(q_s, p_l, lambda_l)\n",
    "        H_l = H_l + self.H_l_u_1(q_s, p_s)*u_s[0]\n",
    "        return H_l\n",
    "            \n",
    "    def compute_lambdas(self, q_s, p_l, u_l):\n",
    "        # not implemented yet\n",
    "        return np.ones((1,self.state_dim))\n",
    "    \n",
    "    def p_rhs_H_l_u(self, q_s, p_l):\n",
    "        return np.array(p_l)\n",
    "    \n",
    "    def q_rhs_H_l_u(self, q_s, p_l):\n",
    "        return np.array(p_l)\n",
    "    \n",
    "    def H_l_D(self, q_lD, p_lD):\n",
    "        return np.array(q_lD).dot(p_lD)\n",
    "        \n",
    "    def L_l_D(self, q_lD, p_lD):\n",
    "        # return scalar\n",
    "        return 1\n",
    "        \n",
    "    def L_l_D_q_Dot(self, q_l_D, q_l_D_Dot):\n",
    "        # return  1-D array of dimension 1 by state_dim,\n",
    "        # each q_lD is a 1-D array of size 1 by state_dim array\n",
    "        return 1\n",
    "\n",
    "    def qp_rhs(self, t, qp_vec, **kwargs):\n",
    "        # u_s is constant (because of causality, remember?)\n",
    "        u_s = kwargs['u_0']\n",
    "        state_dim = kwargs['state_dim']\n",
    "        q_mf = kwargs['q_mf']\n",
    "        u_mf = kwargs['u_mf']\n",
    "        \n",
    "        # TODO:  get a kwargs working for lambda_l\n",
    "        lambda_l = 0 # kwargs['lambda_l']\n",
    "        q_s = qp_vec[:state_dim]\n",
    "        p_l = qp_vec[state_dim:2*state_dim]\n",
    "        p_mf = qp_vec[2*state_dim:]\n",
    "        \n",
    "        qp_rhs_H_mf = self.qp_rhs_H_mf(q_mf, p_mf, u_mf)\n",
    "        q_rhs_H_mf = qp_rhs_H_mf[:state_dim]\n",
    "        p_rhs_H_mf = qp_rhs_H_mf[state_dim:]\n",
    "\n",
    "        qp_rhs_H_l = self.qp_rhs_H_l(q_s, p_l, u_s, lambda_l)\n",
    "        q_rhs_H_l = qp_rhs_H_l[:state_dim]\n",
    "        p_rhs_H_l = qp_rhs_H_l[state_dim:]\n",
    "\n",
    "        q_s_dot = self.gamma*q_rhs_H_mf + (1-self.gamma)*q_rhs_H_l\n",
    "        p_mf_dot = p_rhs_H_mf\n",
    "        p_l_dot = -1*p_rhs_H_l\n",
    "        \n",
    "        return np.concatenate([q_s_dot, p_l_dot, p_mf_dot])\n",
    "    \n",
    "    def qp_rhs_H_l(self, q_s, p_l, u_s, lambda_l):\n",
    "        #TODO: there is one lambda_l per constraint. need to work out dimensions.\n",
    "        q_rhs_H_l = self.q_rhs_H_l_nou(q_s, p_l, lambda_l) + sum([self.q_rhs_H_l_u(q_s, p_l)*u_s_i for u_s_i in u_s])\n",
    "        p_rhs_H_l = self.p_rhs_H_l_nou(q_s, p_l, lambda_l) + sum([self.p_rhs_H_l_u(q_s, p_l)*u_s_i for u_s_i in u_s])\n",
    "        return np.concatenate([q_rhs_H_l, p_rhs_H_l])\n",
    "\n",
    "    def u_rhs(self, t, u_vec, **kwargs):\n",
    "        return -1*self.Gamma*np.zeros(np.shape(u_vec))\n",
    "    \n",
    "    ## Mean Field methods\n",
    "    def H_MF_nou(self, q_s, p_mf):\n",
    "        return 1\n",
    "\n",
    "    def H_MF_u(self, q_mf, p_mf, u_mf):\n",
    "        # q_s, u_mf are vectors for ALL of the states, and controls\n",
    "        # p_mf is a vector for ONLY the local states/costates\n",
    "        # length of u_s must match number of terms here\n",
    "        # some of the elements in u_s are quenched\n",
    "        return self.H_MF_u_1(q_s, p_mf, u_s)*u_mf[0] + self.H_MF_u_2(q_s, p_mf, u_mf)*u_mf[1]\n",
    "\n",
    "    def H_MF_u_1(self, q_mf, p_mf):\n",
    "        return q_mf[0]*q_mf[1]\n",
    "    \n",
    "    def H_MF_u_2(self, q_mf, p_mf):\n",
    "        return q_mf[1]\n",
    "        \n",
    "    def qp_rhs_H_mf(self, q_mf, p_mf, u_s):\n",
    "        # remember that we want to propagate as much as possible together in the same rhs function for numerical purposes\n",
    "        # remember that q_rhs here is w.r.t p_mf but p_rhs here is w.r.t q_s\n",
    "        q_H_mf_dot = self.p_rhs_H_mf(q_mf, p_mf, u_mf, u_s)\n",
    "        p_H_mf_dot = self.q_rhs_H_mf(q_mf, p_mf, u_mf, u_s)\n",
    "        return np.concatenate([q_H_mf_dot, p_H_mf_dot])\n",
    "    \n",
    "    def q_rhs_H_mf(self, q_mf, p_mf, u_mf, u_s):\n",
    "        # q_rhs_H_mf is the derivative wrt each of the local variables, so it will return something of dimension state_dim\n",
    "        # q_rhs_H_mf_u returns the partial derivatives wrt each control, concatenated together\n",
    "        q_rhs_H_mf_u = self.q_rhs_H_mf_u(q_mf, p_mf, u_mf)\n",
    "        assert np.shape(q_rhs_H_mf_u)==(len(self.control_indices), self.state_dim) # first dimension should be number of controls, inner dimension should be state_dim\n",
    "        q_rhs_H_mf_u_summed = sum([q_rhs_H_mf_u[i]*u_s[i] for i in range(len(u_s))])\n",
    "        return self.q_rhs_H_mf_nou(q_mf, p_mf) + q_rhs_H_mf_u_summed\n",
    "        \n",
    "    def q_rhs_H_mf_u(self, q_mf, p_mf, u_mf):\n",
    "        p_H_mf_u_dot_1 =  p_mf # or something\n",
    "        return np.array([p_H_mf_u_dot_1])\n",
    "    \n",
    "    def p_rhs_H_mf(self, q_mf, p_mf, u_mf, u_s):\n",
    "        # q_rhs_H_mf is the derivative wrt each of the local variables, so it will return something of dimension state_dim\n",
    "        # q_rhs_H_mf_u returns the partial derivatives wrt each control, concatenated together\n",
    "        p_rhs_H_mf_u = self.p_rhs_H_mf_u(q_mf, p_mf, u_mf)\n",
    "        p_rhs_H_mf_u_summed = sum([p_rhs_H_mf_u[i]*u_s[i] for i in range(len(u_s))])\n",
    "        return self.p_rhs_H_mf_nou(q_mf, p_mf) + p_rhs_H_mf_u_summed\n",
    "        \n",
    "    def p_rhs_H_mf_nou(self, q_mf, p_mf):\n",
    "        return p_mf # or something\n",
    "\n",
    "    def q_rhs_H_mf_nou(self, q_mf, p_mf):\n",
    "        return p_mf\n",
    "\n",
    "    def p_rhs_H_mf_u(self, q_mf, p_mf, u_mf):\n",
    "        q_H_mf_u_dot = p_mf\n",
    "        return np.array([q_H_mf_u_dot])\n",
    "\n",
    "    def L_mf_q_dot(self, q_mf, q_mf_dot, u_mf):\n",
    "        # q_mf_dot, q_mf (inputs) here will be vectors with ALL of the states\n",
    "        # u_mf is a vector of ALL of the controls\n",
    "        # extract q_s from q_mf\n",
    "        \n",
    "        # note that these methods must return vectors that are of local dimension - state_dim - even though they take in vectors of dimension for all the states\n",
    "        # the user needs to be aware of the indices the correspond to each state\n",
    "        \n",
    "        def L_l_q_dot_agent_1(q_mf, q_mf_dot, u_mf):\n",
    "            return np.array(q_mf[0])\n",
    "        \n",
    "        def L_l_q_dot_agent_2(q_mf, q_mf_dot, u_mf):\n",
    "            return np.array(q_mf[1])\n",
    "        \n",
    "        L_mf_total_q_dot = np.zeros(self.state_dim)\n",
    "\n",
    "        # agent 1\n",
    "        L_mf_total_q_dot += L_l_q_dot_agent_1(q_mf, q_mf_dot, u_mf)\n",
    "\n",
    "        # agent 2\n",
    "        L_mf_total_q_dot += L_l_q_dot_agent_2(q_mf, q_mf_dot, u_mf)\n",
    "        assert np.shape(L_mf_total_q_dot)[0] == self.state_dim, 'dimensions of L_mf_total_q_dot must match those of the local state, currently the dimensions are ' +str(np.shape(L_mf_total_q_dot)[0])\n",
    "        return L_mf_total_q_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Agent2:\n",
    "    \n",
    "    def __init__(self, blackboard, state_indices, control_indices):\n",
    "        '''\n",
    "        state_indices (list of integers): This list tells which states pertain to this agent. e.g. [1,2] would \n",
    "        tell us that states 1 and 2 pertain to this agent.\n",
    "        \n",
    "        A word oNn notation:  The notation used for the methods of the agent is:  \n",
    "            - If it is a partial derivative: <denominator>_rhs_H_<type of hamiltonian (l, mf, or s)>_<nou or u>.  e.g., \n",
    "            \"qp_rhs_H_l_u\" denotes the partial derivative with respect to q and p of the terms in the local Hamiltonian that contain control variables.\n",
    "            - If it is a hamiltonian: H_<type of hamiltonian (l, mf, or s)>_<nou or u>.  e.g. \"H_mf_nou\" denotes the mean field hamiltonian\n",
    "            with terms not containing u.\n",
    "        '''\n",
    "        self.state_indices = state_indices\n",
    "        self.control_indices = control_indices\n",
    "        self.bb = blackboard\n",
    "\n",
    "        # Inputs for numerical propagator\n",
    "        # qp_vec is going to be [q_s, p_l, p_mf], so it will have dimension = 3*state_dim\n",
    "\n",
    "        self.q_s_0 = np.array([0,2])\n",
    "        self.p_l_0 = np.array([0,3])\n",
    "        self.p_mf_0 = np.array([0,1])\n",
    "        self.u_s_0 = np.array([0])\n",
    "        self.qpu_vec = np.hstack([self.q_s_0, self.p_l_0, self.p_mf_0, self.u_s_0])\n",
    "        self.state_dim = 2\n",
    "        self.Gamma = 1 \n",
    "        self.gamma = 1 # gets computed each time the agent is visited\n",
    "        self.q_s_dot = np.array([0,1])  # must have same dimensions as q_s\n",
    "        self.sync = None # gets Synchronizer class is initialized\n",
    "        self.name='Agent2'\n",
    "        \n",
    "        # Inputs for numerical integration\n",
    "        self.integrateTol = 10**-5\n",
    "        self.integrateMaxIter = 400\n",
    "\n",
    "        # Inputs for sliding window\n",
    "        self.t_0 = 0\n",
    "        self.T = 2\n",
    "        self.K = 10\n",
    "\n",
    "        self.t_terminal = 2\n",
    "        self.n_s = 10\n",
    "\n",
    "        self.validate_dimensions()\n",
    "\n",
    "    def validate_dimensions(self):\n",
    "        # TODO: move to parent class \"SlidingWindow\"\n",
    "        assert len(self.state_indices) == self.state_dim, 'state dimensions are not consistent.  dimension of state indices is '+str(len(self.state_indices)) +' and state_dim is '+str(self.state_dim)\n",
    "        assert len(self.control_indices) == len(self.u_s_0), 'control dimensions are not consistent.  dimension of control_indices is '+str(len(self.control_indices)) +' and len(u_0) is '+str(len(self.u_s_0))\n",
    "        assert len(self.qpu_vec) == 3*self.state_dim + len(self.control_indices), ' control and state dimensions are not consistent with qpu_vec : length of qpu_vec is '+str(len(self.qpu_vec))+ ' and 3*self.state_dim + len(self.control_indices) is ' + str(3*self.state_dim + len(self.control_indices))\n",
    "    \n",
    "    '''\n",
    "    TODO:  \n",
    "    Add an assertion to check that the dimension of q_s_0, p_mf_0, and u_0:\n",
    "        - the dimension of state_dim    \n",
    "        - state_indices and control_indices set upon initiation of the Agent\n",
    "        - \n",
    "    '''\n",
    "    \n",
    "    def L_l(self, q_s, q_s_dot, u_s):\n",
    "        return 1\n",
    "    \n",
    "    def L_l_q_dot(self, q_s, q_s_dot, u_s):\n",
    "        return q_s\n",
    "    \n",
    "    def H_l_nou(self, q_s, p_l, lambda_l):\n",
    "        return 1\n",
    "\n",
    "    def p_rhs_H_l_nou(self, q_s, p_l, lambda_l):\n",
    "        return np.array(p_l)\n",
    "    \n",
    "    def q_rhs_H_l_nou(self, q_s, p_l, lambda_l):\n",
    "        return np.array(p_l)\n",
    "\n",
    "    def H_l_u(self, q_s, p_l):\n",
    "        return 1\n",
    "    \n",
    "    def H_l(self, q_s, p_l, lambda_l, u_s):\n",
    "        # used in \"Construct local Hamiltonian of agent i\"\n",
    "        H_l = self.H_l_nou(q_s, p_l, lambda_l)\n",
    "        H_l = H_l + self.H_l_u_1(q_s, p_s)*u_s[0]+ self.H_l_u_2(q_s, p_s)*u_s[1]\n",
    "        return H_l\n",
    "            \n",
    "    def H_MF_u_1(self, q_mf, p_mf):\n",
    "        return q_mf[0]*q_mf[1]\n",
    "    \n",
    "    def H_MF_u_2(self, q_mf, p_mf):\n",
    "        return q_mf[1]\n",
    "    \n",
    "    def compute_lambdas(self, q_s, p_l, u_l):\n",
    "        # not implemented yet\n",
    "        return np.ones((1,self.state_dim))\n",
    "    \n",
    "    def p_rhs_H_l_u(self, q_s, p_l):\n",
    "        return np.array(p_l)\n",
    "    \n",
    "    def q_rhs_H_l_u(self, q_s, p_l):\n",
    "        return np.array(p_l)\n",
    "    \n",
    "    def H_l_D(self, q_lD, p_lD):\n",
    "        return np.array(q_lD).dot(p_lD)\n",
    "        \n",
    "    def L_l_D(self, q_lD, p_lD):\n",
    "        # return scalar\n",
    "        return 1\n",
    "        \n",
    "    def L_l_D_q_Dot(self, q_lD, p_lD):\n",
    "        # return 1 by state_dim, 1-D array\n",
    "        # each q_lD is a 1-D array of size 1 by state_dim array\n",
    "        return 1\n",
    "    \n",
    "    def qp_rhs(self, t, qp_vec, **kwargs):\n",
    "        # u_s is constant (because of causality, remember?)\n",
    "        u_s = kwargs['u_0']\n",
    "        state_dim = kwargs['state_dim']\n",
    "        q_mf = kwargs['q_mf']\n",
    "        u_mf = kwargs['u_mf']\n",
    "        \n",
    "        # TODO:  get a kwargs working for lambda_l\n",
    "        lambda_l = 0 # kwargs['lambda_l']\n",
    "        q_s = qp_vec[:state_dim]\n",
    "        p_l = qp_vec[state_dim:2*state_dim]\n",
    "        p_mf = qp_vec[2*state_dim:]\n",
    "\n",
    "        qp_rhs_H_mf = self.qp_rhs_H_mf(q_mf, p_mf, u_mf, u_s)\n",
    "        p_rhs_H_mf = qp_rhs_H_mf[:state_dim]\n",
    "        q_rhs_H_mf = qp_rhs_H_mf[state_dim:]\n",
    "        \n",
    "        qp_rhs_H_l = self.qp_rhs_H_l(q_s, p_l, u_s, lambda_l)\n",
    "        q_rhs_H_l = qp_rhs_H_l[:state_dim]\n",
    "        p_rhs_H_l = qp_rhs_H_l[state_dim:]\n",
    "\n",
    "        q_s_dot = self.gamma*q_rhs_H_mf + (1-self.gamma)*q_rhs_H_l\n",
    "        p_mf_dot = p_rhs_H_mf\n",
    "        p_l_dot = -1*p_rhs_H_l\n",
    "        \n",
    "        return np.concatenate([q_s_dot, p_l_dot, p_mf_dot])\n",
    "    \n",
    "    def qp_rhs_H_l(self, q_s, p_l, u_s, lambda_l):\n",
    "        #TODO: there is one lambda_l per constraint. need to work out dimensions.\n",
    "        q_rhs_H_l = self.q_rhs_H_l_nou(q_s, p_l, lambda_l) + sum([self.q_rhs_H_l_u(q_s, p_l)*u_s_i for u_s_i in u_s])\n",
    "        p_rhs_H_l = self.p_rhs_H_l_nou(q_s, p_l, lambda_l) + sum([self.p_rhs_H_l_u(q_s, p_l)*u_s_i for u_s_i in u_s])\n",
    "        return np.concatenate([q_rhs_H_l, p_rhs_H_l])\n",
    "\n",
    "    def u_rhs(self, t, u_vec, **kwargs):\n",
    "        u_s = kwargs['u_0']\n",
    "        state_dim = kwargs['state_dim']\n",
    "        q_mf_dot = kwargs['q_mf_dot']\n",
    "        q_s_dot = kwargs['q_s_dot']\n",
    "        p_mf_dot = kwargs['p_mf_dot']\n",
    "        q_mf = kwargs['q_mf']\n",
    "        u_mf = kwargs['u_mf']\n",
    "        p_mf = kwargs['p_mf']\n",
    "        \n",
    "        # don't have q_s_dot, q_mf_dot, or p_mf_dot\n",
    "        def Beta_j(q_mf, p_mf, u_mf, u_s, q_s_dot, q_mf_dot, p_mf_dot, j):\n",
    "            Beta_mf=[]\n",
    "            Beta_l=[]\n",
    "            for k in range(len(self.control_indices)):\n",
    "                Beta_mf_k = self.H_mf_u[j]*(np.dot(self.q_rhs_H_mf_u(p_mf, q_mf, u_mf)[k], q_s_dot) + np.dot(self.p_rhs_H_mf_u(p_mf, q_mf, u_mf)[k], p_mf_dot)) +\n",
    "                            self.H_mf_u[k]*(np.dot(self.q_rhs_H_mf_u(p_mf, q_mf, u_mf)[j], q_s_dot) + np.dot(self.p_rhs_H_mf_u(p_mf, q_mf, u_mf)[j], p_mf_dot))\n",
    "                Beta_l_k = self.H_l_u[j]*(np.dot(self.q_rhs_H_l_u(q_s, p_l)[k], q_s_dot) + np.dot(self.p_rhs_H_l_u(q_s, p_l)[k], p_l_dot)) +\n",
    "                            self.H_l_u[k]*(np.dot(self.q_rhs_H_l_u(q_s, p_l)[j], q_s_dot) + np.dot(self.p_rhs_H_l_u(q_s, p_l)[j], p_l_dot))\n",
    "                \n",
    "#         def alpha_j(q_mf, p_mf, u_mf, u_s, q_s_dot, q_mf_dot, p_mf_dot, j):\n",
    "#             Beta_mf=[]\n",
    "#             Beta_l=[]\n",
    "#             for k in range(len(self.control_indices)):\n",
    "#                 Beta_mf_k = self.H_mf_u[j]*(np.dot(self.q_rhs_H_mf_u(p_mf, q_mf, u_mf)[k], q_s_dot) + np.dot(self.p_rhs_H_mf_u(p_mf, q_mf, u_mf)[k], p_mf_dot)) +\n",
    "#                             self.H_mf_u[k]*(np.dot(self.q_rhs_H_mf_u(p_mf, q_mf, u_mf)[j], q_s_dot) + np.dot(self.p_rhs_H_mf_u(p_mf, q_mf, u_mf)[j], p_mf_dot))\n",
    "#                 Beta_l_k = self.H_l_u[j]*(np.dot(self.q_rhs_H_l_u(q_s, p_l)[k], q_s_dot) + np.dot(self.p_rhs_H_l_u(q_s, p_l)[k], p_l_dot)) +\n",
    "#                             self.H_l_u[k]*(np.dot(self.q_rhs_H_l_u(q_s, p_l)[j], q_s_dot) + np.dot(self.p_rhs_H_l_u(q_s, p_l)[j], p_l_dot))\n",
    "                \n",
    "            \n",
    "        def alpha_mf():\n",
    "        \n",
    "        def Beta_l()\n",
    "        \n",
    "        def alpha_l()\n",
    "        \n",
    "        qp_vec = kwargs['qp_vec']\n",
    "        \n",
    "        u_1_dot = -1*self.Gamma*(self.gamma*(alpha()))\n",
    "        u_2_dot = \n",
    "        u_dot = np.concatenate([]) \n",
    "\n",
    "        return \n",
    "\n",
    "\n",
    "    ## Mean Field methods\n",
    "    def H_MF_nou(self, q_mf, p_mf, u_mf):\n",
    "        return 1\n",
    "\n",
    "    def H_MF_u(self, q_mf, p_mf, u_mf):\n",
    "        return 1\n",
    "        \n",
    "    def qp_rhs_H_mf(self, q_mf, p_mf, u_mf, u_s):\n",
    "        # remember that we want to propagate as much as possible together in the same rhs function for numerical purposes\n",
    "        # remember that q_rhs here is w.r.t p_mf but p_rhs here is w.r.t q_s\n",
    "        q_H_mf_dot = self.p_rhs_H_mf(q_mf, p_mf, u_mf, u_s)\n",
    "        p_H_mf_dot = self.q_rhs_H_mf(q_mf, p_mf, u_mf, u_s)\n",
    "        return np.concatenate([q_H_mf_dot, p_H_mf_dot])\n",
    "    \n",
    "    def q_rhs_H_mf(self, q_mf, p_mf, u_mf, u_s):\n",
    "        # q_rhs_H_mf is the derivative wrt each of the local variables, so it will return something of dimension state_dim\n",
    "        # q_rhs_H_mf_u returns the partial derivatives wrt each control, concatenated together\n",
    "        q_rhs_H_mf_u = self.q_rhs_H_mf_u(q_mf, p_mf, u_mf)\n",
    "        assert np.shape(q_rhs_H_mf_u)==(len(self.control_indices), self.state_dim) # first dimension should be number of controls, inner dimension should be state_dim\n",
    "        q_rhs_H_mf_u_summed = sum([q_rhs_H_mf_u[i]*u_s[i] for i in range(len(u_s))])\n",
    "        return self.q_rhs_H_mf_nou(q_mf, p_mf) + q_rhs_H_mf_u_summed\n",
    "        \n",
    "    def q_rhs_H_mf_u(self, q_mf, p_mf, u_mf):\n",
    "        # this method is will return a concatenation of all of the partial derivatives for each of the controls\n",
    "        # each of the partial derivatives is of dimension state_dim\n",
    "        # this means that this method will return a 2D array:\n",
    "        #    - first dimension is the index of the control\n",
    "        #    - second dimension is the index of the state\n",
    "        p_H_mf_u_dot_1 = p_mf # must be of dimension state_dim\n",
    "        q_rhs_H_mf_u = np.array([p_H_mf_u_dot_1])\n",
    "        return q_rhs_H_mf_u\n",
    "\n",
    "    def p_rhs_H_mf(self, q_mf, p_mf, u_mf, u_s):\n",
    "        # q_rhs_H_mf is the derivative wrt each of the local variables, so it will return something of dimension state_dim\n",
    "        # q_rhs_H_mf_u returns the partial derivatives wrt each control, concatenated together\n",
    "        p_rhs_H_mf_u = self.p_rhs_H_mf_u(q_mf, p_mf, u_mf)\n",
    "        p_rhs_H_mf_u_summed = sum([p_rhs_H_mf_u[i]*u_s[i] for i in range(len(u_s))])\n",
    "        return self.p_rhs_H_mf_nou(q_mf, p_mf) + p_rhs_H_mf_u_summed\n",
    "        \n",
    "    def p_rhs_H_mf_nou(self, q_mf, p_mf):\n",
    "        return  p_mf # or something\n",
    "\n",
    "    def q_rhs_H_mf_nou(self, q_mf, p_mf):\n",
    "        return  p_mf\n",
    "\n",
    "    def p_rhs_H_mf_u(self, q_mf, p_mf, u_mf):\n",
    "        q_H_mf_u_dot = p_mf\n",
    "        return np.array([q_H_mf_u_dot])\n",
    "\n",
    "    def L_mf_q_dot(self, q_mf, q_mf_dot, u_mf):\n",
    "        # q_mf_dot, q_mf (inputs) here will be vectors with ALL of the states\n",
    "        # u_mf is a vector of ALL of the controls\n",
    "        # extract q_s from q_mf\n",
    "        \n",
    "        # note that these methods must return vectors that are of local dimension - state_dim - even though they take in vectors of dimension for all the states\n",
    "        # the user needs to be aware of the indices the correspond to each state\n",
    "\n",
    "        def L_l_q_dot_agent_1(q_mf, q_mf_dot, u_mf):\n",
    "            return np.concatenate([np.array([q_mf[0]]),np.array([q_mf[1]])])\n",
    "        \n",
    "        def L_l_q_dot_agent_2(q_mf, q_mf_dot, u_mf):\n",
    "            return np.concatenate([np.array([q_mf[0]]),np.array([q_mf[1]])])\n",
    "        \n",
    "        L_mf_total_q_dot = np.zeros(self.state_dim)\n",
    "\n",
    "        # agent 1\n",
    "        L_mf_total_q_dot += L_l_q_dot_agent_1(q_mf, q_mf_dot, u_mf)\n",
    "\n",
    "        # agent 2\n",
    "        L_mf_total_q_dot += L_l_q_dot_agent_2(q_mf, q_mf_dot, u_mf)\n",
    "\n",
    "        assert np.shape(L_mf_total_q_dot)[0] == self.state_dim, 'dimensions of L_mf_total_q_dot must match those of the local state, currently the dimensions are ' +str(np.shape(L_mf_total_q_dot)[0])\n",
    "        return L_mf_total_q_dot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### same for p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Synchronizer:\n",
    "    \n",
    "    def __init__(self, agents, blackboard):\n",
    "        self.agents = agents  # list of all agents. list with elements of class Agent\n",
    "        self.bb = blackboard  # instance of class blackboard\n",
    "        \n",
    "        for agent in agents:\n",
    "            self.bb.update_q_p_u_dict(agent)\n",
    "            \n",
    "        # add Synchronizer as to each agent\n",
    "        for agent in agents:\n",
    "            agent.sync = self\n",
    "    \n",
    "    def synchronize(self):\n",
    "        # run synchronization by visiting each agent and running propagation\n",
    "        for agent in self.agents:\n",
    "            '''     \n",
    "            1) run synchronized propagation - I think we only need one Agent instead of SlidingWindow now\n",
    "\n",
    "            For each of the above 2 steps:\n",
    "                - create sliding window instance\n",
    "                - call \"propagate_dynamics\" on the sliding window instance\n",
    "\n",
    "            get quenched values from blackboard\n",
    "            '''\n",
    "            # run propagation with keyword arguments state_dim_l, state_dim_mf\n",
    "            q_ls_bars, p_ls_bars, p_mfs_bars, u_bars, windows = sliding_window(agent)\n",
    "\n",
    "#     def L_mf_q_dot(self, q_mf, q_mf_dot, u_mf):\n",
    "#         # q_mf_dot, q_mf (inputs) here will be vectors with ALL of the states\n",
    "#         # u_mf is a vector of ALL of the controls\n",
    "#         # extract q_s from q_mf\n",
    "#         L_mf_total_q_dot = 0\n",
    "#         for agent in self.agents:\n",
    "#             # Evaluate L_q_dot for each of the agents\n",
    "#             # Remember L_l_q_dot only takes in the local variables.  So, need to know the indices in q_mf which correspond to \n",
    "#             #...the states pertaining to this agent\n",
    "#             q_s = np.array([q_mf[agent.state_indices[state_ix-1]-1] for state_ix in agent.state_indices])\n",
    "#             q_s_dot = np.array([q_mf_dot[agent.state_indices[state_ix-1]-1] for state_ix in agent.state_indices])\n",
    "#             u_s = np.array([u_mf[agent.control_indices[control_ix-1]-1] for control_ix in agent.control_indices])\n",
    "    \n",
    "#             L_l_q_dot = agent.L_l_q_dot(q_s, q_s_dot, u_s)\n",
    "#             L_mf_total_q_dot = L_mf_total_q_dot + L_l_q_dot\n",
    "            \n",
    "#         return L_mf_total_q_dot\n",
    "\n",
    "    def H_mf(self, q_mf, p_mf, u_mf, agent):\n",
    "        # agent is an object of class agent.  It's the agent for which we are constructing H_mf.\n",
    "        # start with H_mf = H_mf_nou, and then add the H_mf_u's\n",
    "\n",
    "        H_mf = agent.H_mf_nou(q_mf, p_mf, u_mf)\n",
    "        H_mf_u = agent.H_mf_u(q_mf, p_mf, u_mf)\n",
    "        H_mf = H_mf + H_mf_u\n",
    "        \n",
    "        return H_mf\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blackboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Blackboard:\n",
    "    \n",
    "    def __init__(self):\n",
    "        '''\n",
    "        values: list of integers state_indices state_indices\n",
    "        q_p_u_dict is a dictionary which maps 'q', 'p', 'u', to a dictionary of index-value pairs: local values for q, p, and u for this agent.  \n",
    "                        blackboard holds all of the most recent local values, e.g.\n",
    "                        {'q_s': {'1':3, '2':0}, 'p_mf': {'1':3, '2': 2}, 'u': {'1': 0}}\n",
    "                        It doesn't care which agent updated them most recently.  It only needs to know which values to update.\n",
    "        q_p_u_dict initially will be filled.\n",
    "        '''\n",
    "        ## TODO:  _s should really be called _mf because it contains all of the states/controls.\n",
    "        self.q_p_u_dict = {'q_s':{}, 'p_l':{}, 'p_mf':{}, 'u_s':{}, 'q_s_dot':{}}\n",
    "        self.agents=[]\n",
    "        \n",
    "    def update_q_p_u_dict(self, agent):\n",
    "        '''This method should be called after propagation of each agent\n",
    "        Inputs:\n",
    "            agent (instance of class Agent): this is the agent whose values we are updating\n",
    "        Outputs:\n",
    "            No outputs.  This method just updates the attributes of the blackboard,\n",
    "            just update the dictionary, agent_q_p_u_dict.\n",
    "        '''\n",
    "        # Determine which states pertain to this agent and replace the old values with new\n",
    "        for state_ix in agent.state_indices:\n",
    "            self.q_p_u_dict['q_s'][str(state_ix)] = agent.qpu_vec[:agent.state_dim][state_ix-1]\n",
    "            self.q_p_u_dict['p_l'][str(state_ix)] = agent.qpu_vec[agent.state_dim:2*agent.state_dim][state_ix-1]\n",
    "            self.q_p_u_dict['p_mf'][str(state_ix)] = agent.qpu_vec[2*agent.state_dim:3*agent.state_dim][state_ix-1]\n",
    "            self.q_p_u_dict['q_s_dot'][str(state_ix)] = agent.q_s_dot[state_ix-1]\n",
    "            \n",
    "        for control_ix in agent.control_indices:\n",
    "            self.q_p_u_dict['u_s'][str(control_ix)] = agent.qpu_vec[3*agent.state_dim:][control_ix-1]\n",
    "        \n",
    "        # update sensor values \"q_l, q_l_dot, u_s\"\n",
    "#         self.q_p_u_dict['q_1'] = [] unnecessary because identical to q_s\n",
    "#         self.q_p_u_dict['q_1_dot'] = []  # numerically estimated, or available from sensors\n",
    "#         self.q_p_u_dict['u_s'] = []  # unnecessary because same as \"u_s\" above\n",
    "        \n",
    "        # add agent if not already added \n",
    "        if agent not in self.agents:\n",
    "            self.agents.append(agent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small test for two agents\n",
    "\n",
    "- Add agents to blackboard and meanfield\n",
    "- Run synchronizer to visit the agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bb = Blackboard()\n",
    "# mean_field = MeanField()\n",
    "\n",
    "myAgent=Agent(bb, state_indices=[1], control_indices=[1])\n",
    "myAgent2=Agent2(bb, state_indices=[1,2], control_indices=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bb.update_q_p_u_dict(myAgent)\n",
    "bb.update_q_p_u_dict(myAgent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q_p_u_dict = bb.q_p_u_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p_l': {'1': 0, '2': 3},\n",
       " 'p_mf': {'1': 0, '2': 1},\n",
       " 'q_s': {'1': 0, '2': 2},\n",
       " 'q_s_dot': {'1': 0, '2': 1},\n",
       " 'u_s': {'1': 0}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_p_u_dict\n",
    "# this only tells us the values of each state/costate.  Does not tell us which ones correspond to which agent\n",
    "# state_indices attribute of each agent tells us which states pertain to the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agents = [myAgent, myAgent2]\n",
    "sync = Synchronizer(agents, bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 2.]]\n",
      "[0. 2. 0. 2.]\n",
      "[0. 2.]\n"
     ]
    }
   ],
   "source": [
    "q_mf, q_mf_dot, u_mf = construct_mf_vectors(myAgent2)\n",
    "q_s, q_s_dot, u_s = construct_local_vectors(myAgent2)\n",
    "\n",
    "# this should return a 2-D array\n",
    "# then, for each of the arrays, we multiply by a scalar value of the control, and add them together.\n",
    "# So,  myAgent2.q_rhs_H_mf(q_mf, q_s, u_mf) should return something of dimension equal to state_dim\n",
    "print myAgent2.q_rhs_H_mf_u(q_mf, q_s, u_mf)\n",
    "\n",
    "print myAgent2.qp_rhs_H_mf(q_mf, q_s, u_mf, u_s) # this should return something of dimension state_dim*2\n",
    "print myAgent2.q_rhs_H_mf(q_mf, q_s, u_mf, u_s) # this should return something of dimension state_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0. 2.]]\n",
      "[0. 2. 0. 2.]\n",
      "[0. 2.]\n"
     ]
    }
   ],
   "source": [
    "# this should return a 2-D array\n",
    "# then, for each of the arrays, we multiply by a scalar value of the control, and add them together.\n",
    "# So,  myAgent2.q_rhs_H_mf(q_mf, q_s, u_mf) should return something of dimension equal to state_dim\n",
    "print myAgent2.p_rhs_H_mf_u(q_mf, q_s, u_mf)\n",
    "\n",
    "print myAgent2.qp_rhs_H_mf(q_mf, q_s, u_mf, u_s) # this should return something of dimension state_dim*2\n",
    "print myAgent2.p_rhs_H_mf(q_mf, q_s, u_mf, u_s) # this should return something of dimension state_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Small test for update_q_mf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "\n",
    "q_mf=np.array([1000,1000])\n",
    "q_mf = update_q_mf(q_mf, q_s, myAgent2)\n",
    "assert q_mf[0] == np.array([0]), 'something went wrong'\n",
    "assert q_mf[1] == np.array([2]), 'something went wrong'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try a very small test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Steps to test qp_rhs and u_rhs:\n",
    "\n",
    "- Give some arbitrary initial conditions\n",
    "- create Agent\n",
    "- create Blackboard\n",
    "- create MeanField\n",
    "- connect those three things above.\n",
    "- somehow create a sliding window instance, or at least wrangle the Agent into a Sliding Window instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# forgot to pass in 'u_s' as a keyword argument\n",
    "qpu_vec, q_ss_bar, p_ls_bar, p_mfs_bar, u_bar, q_ss, p_ls, p_mfs, us, window = propagate_dynamics(myAgent)\n",
    "# forgot to pass in 'u_s' as a keyword argument\n",
    "# qpu_vec2, q_ss_bar2, p_ls_bar2, p_mfs_bar2, u_bar2, q_ss2, p_ls2, p_mfs2, us2 = propagate_dynamics(myAgent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0. 0. 0. 0.] [0.] [0.] [0.] [0.] [array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.])] [array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.])] [array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.])] [array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.])]\n"
     ]
    }
   ],
   "source": [
    "print qpu_vec, q_ss_bar, p_ls_bar, p_mfs_bar, u_bar, q_ss, p_ls, p_mfs, us\n",
    "\n",
    "# print qpu_vec2, q_ss_bar2, p_ls_bar2, p_mfs_bar2, u_bar2, q_ss2, p_ls2, p_mfs2, us2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try another very small test\n",
    "\n",
    "- run propagation for Agent using multiple windows so we can test using initial values, etc.\n",
    "- and we can also test all of the methods for the agent rather than only the one for \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get sliding window working for multiple windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write helper function to take in sliding window, and q_p_u_dict, and return the q_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 0), ('2', 2)]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_p_u_dict['q_s'].items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sliding_window(sliding_window_instance):\n",
    "    ''' \n",
    "    This method runs the propagation for a single agent.  Corresponding to the flow chart it runs:\n",
    "        - Read from blackboard to get the following observation measured at time t_0, and onwards\n",
    "        - construct quenched mean field for Hamiltonian agent i\n",
    "        - Setup initial conditions for L_MF and p_MF\n",
    "        - Construct agent synchronized Hamiltonian and partial derivatives\n",
    "    \n",
    "    Inputs:\n",
    "    The only input is sliding_window_instance, but we use the following attributes of the sliding_window_instance:\n",
    "        t_0 (int): Initial time to start propagating dynamics\n",
    "        T (int): End time of propagating dynamics\n",
    "        q_0 (np.array): initial values of state vector\n",
    "        p_0 (np.array): initial values of costate vector\n",
    "        u_0 (np.array): initial values of control vector\n",
    "        state_dim (int): number of states\n",
    "        Gamma (float): algorithmic parameter for Riemann descent algorithm\n",
    "        t_terminal (int): time marking termination of control law propagator algorithm\n",
    "    Outputs:\n",
    "        q_bars, p_bars, u_bars (list of np.arrays): implemented state/costate/control values for entire propagator.\n",
    "    '''\n",
    "    \n",
    "    t_0, T, K, state_dim,t_terminal = sliding_window_instance.t_0, sliding_window_instance.T, sliding_window_instance.K,  sliding_window_instance.state_dim, sliding_window_instance.t_terminal\n",
    "    q_ls_bars, p_ls_bars, p_mfs_bars, u_bars, windows = [], [], [], [], []\n",
    "    t = t_0 # wall clock time\n",
    "    \n",
    "    # Read from blackboard to get the following observations measured at time t_0\n",
    "    q_s_0, q_s_dot_0, u_s_0 = construct_local_vectors(sliding_window_instance)\n",
    "    q_mf, q_mf_dot, u_mf = construct_mf_vectors(sliding_window_instance)\n",
    "\n",
    "    # now pick out the individual states that we need to make q_s and q_s_dot\n",
    "    qpu_vec = sliding_window_instance.qpu_vec\n",
    "    state_dim = sliding_window_instance.state_dim\n",
    "    # a note on q_s_dot - normally I understand that this would come from the sensors, ...\n",
    "    # ...but for now get it from q_mf_dot from the blackboard, and just select if from the states that pertain to this agent\n",
    "    # construct quenched mean field for Hamiltonian agent i\n",
    "    # this happens inside of the class Synchronize method\n",
    "    \n",
    "    # If control is physical, then we should use the physical value here for initial condition\n",
    "    # IF not, then we can use the average u, averaged over the previous window.\n",
    "    # For now, use the value from the blackboard\n",
    "    q_l_D_dot_0 = q_s_dot_0\n",
    "    q_l_D_0 = q_s_0\n",
    "\n",
    "    # set initial conditions using values from blackboard retrieved above\n",
    "    # set initial conditions for local Hamiltonian of agent i\n",
    "    p_l_0 = sliding_window_instance.L_l_q_dot(q_s_0, q_s_dot_0, u_s_0) # compute using Dirac compatibility\n",
    "    p_l_D_0 = sliding_window_instance.L_l_D_q_Dot(q_l_D_0, q_l_D_dot_0) # compute using Dirac compatibility\n",
    "    H_l_D_0 = sliding_window_instance.H_l_D(q_l_D_0, p_l_D_0)\n",
    "    \n",
    "    # setup initial condition for p_mf\n",
    "    p_mf_0 = sliding_window_instance.L_mf_q_dot(q_mf, q_mf_dot, u_mf)\n",
    "    \n",
    "    # now construct qpu_vec \n",
    "    sliding_window_instance.qpu_vec = np.concatenate([q_s_0, p_l_0, p_mf_0, u_s_0]) # fill in with blackboard values for q and u, but for p, must be computed\n",
    "    # Construct local Hamiltonian of agent i\n",
    "    lambdas = sliding_window_instance.compute_lambdas(q_s_0, p_l_0, u_s_0)\n",
    "\n",
    "    while t < sliding_window_instance.t_terminal:\n",
    "        \n",
    "        # for the times, propagate_dynamics needs: t_0, T, and K.  T and K can come from the sliding_window_instance\n",
    "        #...t_0 will be passed in.  t_0 is the start of the window.\n",
    "\n",
    "        # this propagates a single window\n",
    "        # inside of propagate dynamics\n",
    "        qpu_vec, q_ls_bar, p_ls_bar, p_mfs_bar, u_bar, q_ls, p_ls, p_mfs, us, window = propagate_dynamics(sliding_window_instance)\n",
    "        # qs, ps, and us will go to Mean Field somehow\n",
    "        \n",
    "        q_ls_bars.append(q_ls_bar)\n",
    "        p_ls_bars.append(p_ls_bar)\n",
    "        p_mfs_bars.append(p_mfs_bar)\n",
    "        u_bars.append(u_bar)\n",
    "        windows.append(window)\n",
    "\n",
    "        t+=1\n",
    "    # update blackboard\n",
    "    bb.update_q_p_u_dict(sliding_window_instance)\n",
    "    \n",
    "    return q_ls_bars, p_ls_bars, p_mfs_bars, u_bars, windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myAgent.qpu_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q_ls_bars, p_ls_bars, p_mfs_bars, u_bars, windows = sliding_window(myAgent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 2]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myAgent2.q_rhs_H_mf_u(p_mfs_bar[0],q_mf,u_mf)[k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "Agent2 instance has no attribute 'u_rhs'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-758a6e195c16>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mqpu_vec2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_ss_bar2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_ls_bar2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_mfs_bar2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_bar2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_ss2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_ls2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_mfs2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mus2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpropagate_dynamics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmyAgent2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Users/jordan/Documents/Atigeo/cdi/control_law_propagator/sliding_window.py\u001b[0m in \u001b[0;36mpropagate_dynamics\u001b[0;34m(sliding_window_instance)\u001b[0m\n\u001b[1;32m    161\u001b[0m         \u001b[0;31m# prepend initial condition for q and p for propagating u\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    162\u001b[0m         \u001b[0mlhs_qp_vecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mqpu_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mqp_vecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# last item in qpu_vec is \"u\", so leave it out. last item in qp_vecs is the last point in propagation (since we are using left hand side of q and p - leave it out.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 163\u001b[0;31m         \u001b[0mu_vecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpropagate_u\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlhs_qp_vecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msliding_window_instance\u001b[0m\u001b[0;34m)\u001b[0m      \u001b[0;31m# pass in the resulting lhs q and p values to be used for propagating the \"u\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    164\u001b[0m         \u001b[0;31m# again t=0.0 doesn't matter what the value is here because derivative is not a function of time anyway (it's time invariant)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    165\u001b[0m         \u001b[0mu_dot_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msliding_window_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mu_rhs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_vecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msliding_window_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msliding_window_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqp_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqp_vecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jordan/Documents/Atigeo/cdi/control_law_propagator/sliding_window.py\u001b[0m in \u001b[0;36mpropagate_u\u001b[0;34m(u_0, qp_vecs, t_start, t_end, sliding_window_instance)\u001b[0m\n\u001b[1;32m    261\u001b[0m         \u001b[0mn_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_end\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    262\u001b[0m         \u001b[0mqp_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqp_vecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 263\u001b[0;31m         \u001b[0mu_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfailFlag\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miter_i\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mode_rk23\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msliding_window_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mu_rhs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msliding_window_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrateTol\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msliding_window_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegrateMaxIter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msliding_window_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mGamma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msliding_window_instance\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGamma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqp_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqp_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    264\u001b[0m         \u001b[0mu_vecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mu_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# one u_vec for each step, append them and you have all the u_vecs for one bucket\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    265\u001b[0m         \u001b[0mu_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mu_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Agent2 instance has no attribute 'u_rhs'"
     ]
    }
   ],
   "source": [
    "qpu_vec2, q_ss_bar2, p_ls_bar2, p_mfs_bar2, u_bar2, q_ss2, p_ls2, p_mfs2, us2 = propagate_dynamics(myAgent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sync.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
