{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the prototype of the Mean Field\n",
    "\n",
    "There will be three main modules:\n",
    "\n",
    "- 1) Agent\n",
    "\n",
    "- 2) MeanField\n",
    "\n",
    "- 3) BlackBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>.container { width:100% !important; }</style>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.core.display import display, HTML\n",
    "display(HTML(\"<style>.container { width:100% !important; }</style>\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy as sp\n",
    "import ode\n",
    "from sliding_window import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Agent:\n",
    "    \n",
    "    def __init__(self, blackboard, state_indices, control_indices):\n",
    "        '''\n",
    "        state_indices (list of integers): This list tells which states pertain to this agent. e.g. [1,2] would \n",
    "        tell us that states 1 and 2 pertain to this agent.\n",
    "        \n",
    "        A word on notation:  The notation used for the methods of the agent is:  \n",
    "            - If it is a partial derivative: <denominator>_rhs_H_<type of hamiltonian (l, mf, or s)>_<nou or u>.  e.g., \n",
    "            \"qp_rhs_H_l_u\" denotes the partial derivative with respect to q and p of the terms in the local Hamiltonian that contain control variables.\n",
    "            - If it is a hamiltonian: H_<type of hamiltonian (l, mf, or s)>_<nou or u>.  e.g. \"H_mf_nou\" denotes the mean field hamiltonian\n",
    "            with terms not containing u.\n",
    "        '''\n",
    "        self.state_indices = state_indices\n",
    "        self.control_indices = control_indices\n",
    "        self.bb = blackboard\n",
    "\n",
    "        # Inputs for numerical propagator\n",
    "        # qp_vec is going to be [q_s, p_l, p_mf], so it will have dimension = 3*state_dim\n",
    "\n",
    "        self.q_s_0 = np.array([0])\n",
    "        self.p_l_0 = np.array([0])\n",
    "        self.p_mf_0 = np.array([0])\n",
    "        self.u_s_0 = np.array([0])\n",
    "        self.qpu_vec = np.hstack([self.q_s_0, self.p_l_0, self.p_mf_0, self.u_s_0])\n",
    "        self.q_s_dot = np.array([0])  # must have same dimensions as q_s\n",
    "        self.state_dim = 1\n",
    "        self.Gamma = 1\n",
    "        self.gamma = 1  # function is inputted by the user to compute this.\n",
    "        self.sync = None # gets filled in when Synchronizer class is initialized\n",
    "\n",
    "        # Inputs for numerical integration\n",
    "        self.integrateTol = 10**-5\n",
    "        self.integrateMaxIter = 400\n",
    "\n",
    "        # Inputs for sliding window\n",
    "        self.t_0 = 0 \n",
    "        self.T =  2\n",
    "        self.K=10\n",
    "\n",
    "        self.t_terminal = 4\n",
    "        self.n_s = 10\n",
    "\n",
    "        self.validate_dimensions()\n",
    "        \n",
    "    def compute_gamma(self):\n",
    "        # if only one agent, then gamma = 1\n",
    "        if len(self.bb.agents) == 1:\n",
    "            return 1\n",
    "        q_s, p_l, p_mf, u_s = self.qpu_vec\n",
    "        q_s_dot = self.q_s_dot\n",
    "        num = self.L_l(q_s, q_s_dot, u_s)\n",
    "        denom = 0\n",
    "\n",
    "        assert len(self.bb.agents) != 0, 'Add agents to your blackboard by calling bb.update_q_p_u_dict(<agent>)'\n",
    "        for agent in self.bb.agents:\n",
    "            denom += agent.L_l(q_s, q_s_dot, u_s)\n",
    "        self.gamma = float(num)/float(denom)\n",
    "        \n",
    "\n",
    "    def validate_dimensions(self):\n",
    "        # TODO: move to parent class \"SlidingWindow\"\n",
    "        assert len(self.state_indices) == self.state_dim, 'state dimensions are not consistent.  dimension of state indices is '+str(len(self.state_indices)) +' and state_dim is '+str(self.state_dim)\n",
    "        assert len(self.control_indices) == len(self.u_s_0), 'control dimensions are not consistent.  dimension of control_indices is '+str(len(self.control_indices)) +' and len(u_0) is '+str(len(self.u_s_0))\n",
    "        assert len(self.qpu_vec) == 3*self.state_dim + len(self.control_indices), ' control and state dimensions are not consistent with qpu_vec : length of qpu_vec is '+str(len(self.qpu_vec))+ ' and 3*self.state_dim + len(self.control_indices) is ' + str(3*self.state_dim + len(self.control_indices))\n",
    "    \n",
    "    '''\n",
    "    TODO:  \n",
    "    Add an assertion to check that the dimension of q_s_0, p_mf_0, and u_0:\n",
    "        - the dimension of state_dim\n",
    "        - state_indices and control_indices set upon initiation of the Agent\n",
    "    '''\n",
    "    \n",
    "    def L_l(self, q_s, q_s_dot, u_s):\n",
    "        return 1\n",
    "    \n",
    "    def L_l_q_dot(self, q_s, q_s_dot, u_s):\n",
    "        return q_s\n",
    "    \n",
    "    def H_l_nou(self, q_s, p_l, lambda_l):\n",
    "        return 1\n",
    "\n",
    "    def p_rhs_H_l_nou(self, q_s, p_l, lambda_l):\n",
    "        return np.array(p_l)\n",
    "    \n",
    "    def q_rhs_H_l_nou(self, q_s, p_l, lambda_l):\n",
    "        return np.array(p_l)\n",
    "    \n",
    "    # There should be one of these defined for each control variable\n",
    "\n",
    "    def H_l_u_1(self, q_s, p_s):\n",
    "        return 1\n",
    "    \n",
    "    def H_l(self, q_s, p_l, lambda_l, u_s):\n",
    "        # used in \"Construct local Hamiltonian of agent i\"\n",
    "        H_l = self.H_l_nou(q_s, p_l, lambda_l)\n",
    "        H_l = H_l + self.H_l_u_1(q_s, p_s)*u_s[0]\n",
    "        return H_l\n",
    "            \n",
    "    def compute_lambdas(self, q_s, p_l, u_l):\n",
    "        # not implemented yet\n",
    "        return np.ones((1,self.state_dim))\n",
    "    \n",
    "    def p_rhs_H_l_u(self, q_s, p_l):\n",
    "        return np.array(p_l)\n",
    "    \n",
    "    def q_rhs_H_l_u(self, q_s, p_l):\n",
    "        return np.array(p_l)\n",
    "    \n",
    "    def H_l_D(self, q_lD, p_lD):\n",
    "        return np.array(q_lD).dot(p_lD)\n",
    "        \n",
    "    def L_l_D(self, q_lD, p_lD):\n",
    "        # return scalar\n",
    "        return 1\n",
    "        \n",
    "    def L_l_D_q_Dot(self, q_l_D, q_l_D_Dot):\n",
    "        # return  1-D array of dimension 1 by state_dim,\n",
    "        # each q_lD is a 1-D array of size 1 by state_dim array\n",
    "        return 1\n",
    "\n",
    "    def qp_rhs(self, t, qp_vec, **kwargs):\n",
    "        # u_s is constant (because of causality, remember?)\n",
    "        u_s = kwargs['u_0']\n",
    "        state_dim = kwargs['state_dim']\n",
    "        q_mf = kwargs['q_mf']\n",
    "        u_mf = kwargs['u_mf']\n",
    "        \n",
    "        # TODO:  get a kwargs working for lambda_l\n",
    "        lambda_l = 0 # kwargs['lambda_l']\n",
    "        q_s = qp_vec[:state_dim]\n",
    "        p_l = qp_vec[state_dim:2*state_dim]\n",
    "        p_mf = qp_vec[2*state_dim:]\n",
    "        \n",
    "        qp_rhs_H_mf = self.qp_rhs_H_mf(q_s, p_mf, u_mf)\n",
    "        q_rhs_H_mf = qp_rhs_H_mf[:state_dim]\n",
    "        p_rhs_H_mf = qp_rhs_H_mf[state_dim:]\n",
    "\n",
    "        qp_rhs_H_l = self.qp_rhs_H_l(q_s, p_l, u_s, lambda_l)\n",
    "        q_rhs_H_l = qp_rhs_H_l[:state_dim]\n",
    "        p_rhs_H_l = qp_rhs_H_l[state_dim:]\n",
    "\n",
    "        q_s_dot = self.gamma*q_rhs_H_mf + (1-self.gamma)*q_rhs_H_l\n",
    "        p_mf_dot = p_rhs_H_mf\n",
    "        p_l_dot = -1*p_rhs_H_l\n",
    "        \n",
    "        return np.concatenate([q_s_dot, p_l_dot, p_mf_dot])\n",
    "    \n",
    "    def qp_rhs_H_l(self, q_s, p_l, u_s, lambda_l):\n",
    "        #TODO: there is one lambda_l per constraint. need to work out dimensions.\n",
    "        q_rhs_H_l = self.q_rhs_H_l_nou(q_s, p_l, lambda_l) + sum([self.q_rhs_H_l_u(q_s, p_l)*u_s_i for u_s_i in u_s])\n",
    "        p_rhs_H_l = self.p_rhs_H_l_nou(q_s, p_l, lambda_l) + sum([self.p_rhs_H_l_u(q_s, p_l)*u_s_i for u_s_i in u_s])\n",
    "        return np.concatenate([q_rhs_H_l, p_rhs_H_l])\n",
    "\n",
    "\n",
    "    ## Mean Field methods\n",
    "    def H_MF_nou(self, q_s, p_mf):\n",
    "        return 1\n",
    "\n",
    "    def H_MF_u(self, q_mf, p_mf, u_mf):\n",
    "        # q_s, u_mf are vectors for ALL of the states, and controls\n",
    "        # p_mf is a vector for ONLY the local states/costates\n",
    "        # length of u_s must match number of terms here\n",
    "        # some of the elements in u_s are quenched\n",
    "        return self.H_MF_u_1(q_s, p_mf, u_s)*u_mf[0] + self.H_MF_u_2(q_s, p_mf, u_mf)*u_mf[1]\n",
    "\n",
    "    def H_MF_u_1(self, q_mf, p_mf):\n",
    "        return q_mf[0]*q_mf[1]\n",
    "    \n",
    "    def H_MF_u_2(self, q_mf, p_mf):\n",
    "        return q_mf[1]\n",
    "        \n",
    "    def qp_rhs_H_mf(self, q_mf, p_mf, u_s):\n",
    "        # remember that we want to propagate as much as possible together in the same rhs function for numerical purposes\n",
    "        # remember that q_rhs here is w.r.t p_mf but p_rhs here is w.r.t q_s\n",
    "        q_H_mf_dot = self.p_rhs_H_mf(q_mf, p_mf, u_s)\n",
    "        p_H_mf_dot = self.q_rhs_H_mf(q_mf, p_mf, u_s)\n",
    "        return np.concatenate([q_H_mf_dot, p_H_mf_dot])\n",
    "    \n",
    "    def q_rhs_H_mf(self, q_mf, p_mf, u_s):\n",
    "        return self.q_rhs_H_mf_nou(q_mf, p_mf) + sum([self.q_rhs_H_mf_u(q_mf, p_mf)*u_i for u_i in u_s])\n",
    "        \n",
    "    def q_rhs_H_mf_u(self, q_s, p_mf):\n",
    "        # there should be one of these methods for EACH control variable\n",
    "        assert np.shape(q_s)==np.shape(p_mf), 'shapes for q_s and p_mf are not equal'\n",
    "        p_H_mf_u_dot_1 = q_s + p_mf # or something\n",
    "        return np.concatenate([p_H_mf_u_dot_1])\n",
    "    \n",
    "    def p_rhs_H_mf(self, q_s, p_mf, u_s):\n",
    "        return self.p_rhs_H_mf_nou(q_s, p_mf) + sum([self.p_rhs_H_mf_u(q_s, p_mf)*u_i for u_i in u_s])\n",
    "\n",
    "    def p_rhs_H_mf_nou(self, q_s, p_mf):\n",
    "        return q_s + p_mf # or something\n",
    "\n",
    "    def q_rhs_H_mf_nou(self, q_s, p_mf):\n",
    "        return  q_s + p_mf\n",
    "\n",
    "    def p_rhs_H_mf_u(self, q_s, p_mf):\n",
    "        q_H_mf_u_dot = q_s + p_mf\n",
    "        return np.concatenate([q_H_mf_u_dot])\n",
    "\n",
    "    def L_mf_q_dot(self, q_mf, q_mf_dot, u_mf):\n",
    "        # q_mf_dot, q_mf (inputs) here will be vectors with ALL of the states\n",
    "        # u_mf is a vector of ALL of the controls\n",
    "        # extract q_s from q_mf\n",
    "        \n",
    "        # note that these methods must return vectors that are of local dimension - state_dim - even though they take in vectors of dimension for all the states\n",
    "        # the user needs to be aware of the indices the correspond to each state\n",
    "        \n",
    "        def L_l_q_dot_agent_1(q_mf, q_mf_dot, u_mf):\n",
    "            return np.array(q_mf[0])\n",
    "        \n",
    "        def L_l_q_dot_agent_2(q_mf, q_mf_dot, u_mf):\n",
    "            return np.array(q_mf[1])\n",
    "        \n",
    "        L_mf_total_q_dot = np.zeros(self.state_dim)\n",
    "\n",
    "        # agent 1\n",
    "        L_mf_total_q_dot += L_l_q_dot_agent_1(q_mf, q_mf_dot, u_mf)\n",
    "\n",
    "        # agent 2\n",
    "        L_mf_total_q_dot += L_l_q_dot_agent_2(q_mf, q_mf_dot, u_mf)\n",
    "        assert np.shape(L_mf_total_q_dot)[0] == self.state_dim, 'dimensions of L_mf_total_q_dot must match those of the local state, currently the dimensions are ' +str(np.shape(L_mf_total_q_dot)[0])\n",
    "        return L_mf_total_q_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Agent2:\n",
    "    \n",
    "    def __init__(self, blackboard, state_indices, control_indices):\n",
    "        '''\n",
    "        state_indices (list of integers): This list tells which states pertain to this agent. e.g. [1,2] would \n",
    "        tell us that states 1 and 2 pertain to this agent.\n",
    "        \n",
    "        A word oNn notation:  The notation used for the methods of the agent is:  \n",
    "            - If it is a partial derivative: <denominator>_rhs_H_<type of hamiltonian (l, mf, or s)>_<nou or u>.  e.g., \n",
    "            \"qp_rhs_H_l_u\" denotes the partial derivative with respect to q and p of the terms in the local Hamiltonian that contain control variables.\n",
    "            - If it is a hamiltonian: H_<type of hamiltonian (l, mf, or s)>_<nou or u>.  e.g. \"H_mf_nou\" denotes the mean field hamiltonian\n",
    "            with terms not containing u.\n",
    "        '''\n",
    "        self.state_indices = state_indices\n",
    "        self.control_indices = control_indices\n",
    "        self.bb = blackboard\n",
    "\n",
    "        # Inputs for numerical propagator\n",
    "        # qp_vec is going to be [q_s, p_l, p_mf], so it will have dimension = 3*state_dim\n",
    "\n",
    "        self.q_s_0 = np.array([0,2])\n",
    "        self.p_l_0 = np.array([0,3])\n",
    "        self.p_mf_0 = np.array([0,1])\n",
    "        self.u_s_0 = np.array([0])\n",
    "        self.qpu_vec = np.hstack([self.q_s_0, self.p_l_0, self.p_mf_0, self.u_s_0])\n",
    "        self.state_dim = 2\n",
    "        self.Gamma = 1 \n",
    "        self.gamma = 1 # gets computed each time the agent is visited\n",
    "        self.q_s_dot = np.array([0,1])  # must have same dimensions as q_s\n",
    "        self.sync = None # gets Synchronizer class is initialized\n",
    "        \n",
    "        # Inputs for numerical integration\n",
    "        self.integrateTol = 10**-5\n",
    "        self.integrateMaxIter = 400\n",
    "\n",
    "        # Inputs for sliding window\n",
    "        self.t_0 = 0\n",
    "        self.T = 2\n",
    "        self.K = 10\n",
    "\n",
    "        self.t_terminal = 2\n",
    "        self.n_s = 10\n",
    "\n",
    "        self.validate_dimensions()\n",
    "\n",
    "    def validate_dimensions(self):\n",
    "        # TODO: move to parent class \"SlidingWindow\"\n",
    "        assert len(self.state_indices) == self.state_dim, 'state dimensions are not consistent.  dimension of state indices is '+str(len(self.state_indices)) +' and state_dim is '+str(self.state_dim)\n",
    "        assert len(self.control_indices) == len(self.u_s_0), 'control dimensions are not consistent.  dimension of control_indices is '+str(len(self.control_indices)) +' and len(u_0) is '+str(len(self.u_s_0))\n",
    "        assert len(self.qpu_vec) == 3*self.state_dim + len(self.control_indices), ' control and state dimensions are not consistent with qpu_vec : length of qpu_vec is '+str(len(self.qpu_vec))+ ' and 3*self.state_dim + len(self.control_indices) is ' + str(3*self.state_dim + len(self.control_indices))\n",
    "    \n",
    "    '''\n",
    "    TODO:  \n",
    "    Add an assertion to check that the dimension of q_s_0, p_mf_0, and u_0:\n",
    "        - the dimension of state_dim    \n",
    "        - state_indices and control_indices set upon initiation of the Agent\n",
    "        - \n",
    "    '''\n",
    "    \n",
    "    def L_l(self, q_s, q_s_dot, u_s):\n",
    "        return 1\n",
    "    \n",
    "    def L_l_q_dot(self, q_s, q_s_dot, u_s):\n",
    "        return q_s\n",
    "    \n",
    "    def H_l_nou(self, q_s, p_l, lambda_l):\n",
    "        return 1\n",
    "\n",
    "    def p_rhs_H_l_nou(self, q_s, p_l, lambda_l):\n",
    "        return np.array(p_l)\n",
    "    \n",
    "    def q_rhs_H_l_nou(self, q_s, p_l, lambda_l):\n",
    "        return np.array(p_l)\n",
    "\n",
    "    def H_l_u(self, q_s, p_l):\n",
    "        return 1\n",
    "    \n",
    "    def H_l(self, q_s, p_l, lambda_l, u_s):\n",
    "        # used in \"Construct local Hamiltonian of agent i\"\n",
    "        H_l = self.H_l_nou(q_s, p_l, lambda_l)\n",
    "        H_l = H_l + self.H_l_u_1(q_s, p_s)*u_s[0]+ self.H_l_u_2(q_s, p_s)*u_s[1]\n",
    "        return H_l\n",
    "            \n",
    "    def H_MF_u_1(self, q_mf, p_mf):\n",
    "        return q_mf[0]*q_mf[1]\n",
    "    \n",
    "    def H_MF_u_2(self, q_mf, p_mf):\n",
    "        return q_mf[1]\n",
    "    \n",
    "    def compute_lambdas(self, q_s, p_l, u_l):\n",
    "        # not implemented yet\n",
    "        return np.ones((1,self.state_dim))\n",
    "    \n",
    "    def p_rhs_H_l_u(self, q_s, p_l):\n",
    "        return np.array(p_l)\n",
    "    \n",
    "    def q_rhs_H_l_u(self, q_s, p_l):\n",
    "        return np.array(p_l)\n",
    "    \n",
    "    def H_l_D(self, q_lD, p_lD):\n",
    "        return np.array(q_lD).dot(p_lD)\n",
    "        \n",
    "    def L_l_D(self, q_lD, p_lD):\n",
    "        # return scalar\n",
    "        return 1\n",
    "        \n",
    "    def L_l_D_q_Dot(self, q_lD, p_lD):\n",
    "        # return 1 by state_dim, 1-D array\n",
    "        # each q_lD is a 1-D array of size 1 by state_dim array\n",
    "        return 1\n",
    "    \n",
    "    def qp_rhs(self, t, qp_vec, **kwargs):\n",
    "        # u_s is constant (because of causality, remember?)\n",
    "        u_s = kwargs['u_0']\n",
    "        state_dim = kwargs['state_dim']\n",
    "        q_mf = kwargs['q_mf']\n",
    "        u_mf = kwargs['u_mf']\n",
    "        \n",
    "        # TODO:  get a kwargs working for lambda_l\n",
    "        lambda_l = 0 # kwargs['lambda_l']\n",
    "        q_s = qp_vec[:state_dim]\n",
    "        p_l = qp_vec[state_dim:2*state_dim]\n",
    "        p_mf = qp_vec[2*state_dim:]\n",
    "\n",
    "        qp_rhs_H_mf = self.qp_rhs_H_mf(q_mf, p_mf, u_mf)\n",
    "        p_rhs_H_mf = qp_rhs_H_mf[:state_dim]\n",
    "        q_rhs_H_mf = qp_rhs_H_mf[state_dim:]\n",
    "        qp_rhs_H_l = self.qp_rhs_H_l(q_s, p_l, u_s, lambda_l)\n",
    "        q_rhs_H_l = qp_rhs_H_l[:state_dim]\n",
    "        p_rhs_H_l = qp_rhs_H_l[state_dim:]\n",
    "\n",
    "        q_s_dot = self.gamma*q_rhs_H_mf + (1-self.gamma)*q_rhs_H_l\n",
    "        p_mf_dot = p_rhs_H_mf\n",
    "        p_l_dot = -1*p_rhs_H_l\n",
    "        \n",
    "        return np.concatenate([q_s_dot, p_l_dot, p_mf_dot])\n",
    "    \n",
    "    def qp_rhs_H_l(self, q_s, p_l, u_s, lambda_l):\n",
    "        #TODO: there is one lambda_l per constraint. need to work out dimensions.\n",
    "        q_rhs_H_l = self.q_rhs_H_l_nou(q_s, p_l, lambda_l) + sum([self.q_rhs_H_l_u(q_s, p_l)*u_s_i for u_s_i in u_s])\n",
    "        p_rhs_H_l = self.p_rhs_H_l_nou(q_s, p_l, lambda_l) + sum([self.p_rhs_H_l_u(q_s, p_l)*u_s_i for u_s_i in u_s])\n",
    "        return np.concatenate([q_rhs_H_l, p_rhs_H_l])\n",
    "\n",
    "    def u_rhs(self, t, u_vec, **kwargs):\n",
    "        \n",
    "#         def Beta_mf(q_mf, p_mf):\n",
    "#             self.H_MF_u_1(q_mf, p_mf)*(self.q_rhs_H_mf_u_1(q_s, p_mf))\n",
    "        \n",
    "#         def alpha_mf():\n",
    "        \n",
    "#         def Beta_l()\n",
    "        \n",
    "#         def alpha_l()\n",
    "        \n",
    "        qp_vec = kwargs['qp_vec']\n",
    "        \n",
    "        # -1*self.Gamma*(self.gamma)\n",
    "#         u_1_dot = -1*self.Gamma*(self.gamma*(alpha()))\n",
    "#         u_2_dot = \n",
    "#         u_dot = np.concatenate([]) \n",
    "\n",
    "        return -1*self.Gamma*np.zeros(np.shape(u_vec))\n",
    "\n",
    "#     def q_rhs_H_mf_u_1(self, q_mf, p_mf):\n",
    "                                 \n",
    "                                 \n",
    "#     def q_rhs_H_mf_u_2(self, q_mf, p_mf):\n",
    "        \n",
    "\n",
    "    ## Mean Field methods\n",
    "    def H_MF_nou(self, q_mf, p_mf, u_mf):\n",
    "        return 1\n",
    "\n",
    "    def H_MF_u(self, q_mf, p_mf, u_mf):\n",
    "        return 1\n",
    "        \n",
    "    def qp_rhs_H_mf(self, q_mf, p_mf, u_s):\n",
    "        # remember that we want to propagate as much as possible together in the same rhs function for numerical purposes\n",
    "        # remember that q_rhs here is w.r.t p_mf but p_rhs here is w.r.t q_s\n",
    "        q_H_mf_dot = self.p_rhs_H_mf(q_mf, p_mf, u_s)\n",
    "        p_H_mf_dot = self.q_rhs_H_mf(q_mf, p_mf, u_s)\n",
    "        return np.concatenate([q_H_mf_dot, p_H_mf_dot])\n",
    "    \n",
    "    def q_rhs_H_mf(self, q_mf, p_mf, u_s):\n",
    "        # q_rhs_H_mf_u returns something                                  \n",
    "        q_rhs_H_mf_u = sum([self.q_rhs_H_mf_u(q_s, p_mf)[i]*u_s[i] for i in range(len(u_s))])\n",
    "        return self.q_rhs_H_mf_nou(q_mf, p_mf) + q_rhs_H_mf_u\n",
    "        \n",
    "    def q_rhs_H_mf_u(self, q_s, p_mf):\n",
    "        # this method is will return a concatenation of all of the partial derivatives for each of the controls\n",
    "        assert np.shape(q_s) == np.shape(p_mf), 'shapes for q_s and p_mf are not equal'\n",
    "        p_H_mf_u_dot_1 = q_s + p_mf # or something\n",
    "        p_H_mf_u_dot_2 = q_s + 2*p_mf # or something\n",
    "        return np.concatenate([p_H_mf_u_dot_1, p_H_mf_u_dot_2])\n",
    "\n",
    "    def p_rhs_H_mf(self, q_s, p_mf, u_s):\n",
    "        return self.p_rhs_H_mf_nou(q_s, p_mf) + sum([self.p_rhs_H_mf_u(q_s, p_mf)*u_i for u_i in u_s])\n",
    "\n",
    "    def p_rhs_H_mf_nou(self, q_s, p_mf):\n",
    "        return q_s + p_mf # or something\n",
    "\n",
    "    def q_rhs_H_mf_nou(self, q_s, p_mf):\n",
    "        return  q_s + p_mf\n",
    "\n",
    "    def p_rhs_H_mf_u(self, q_s, p_mf):\n",
    "        q_H_mf_u_dot = q_s + p_mf\n",
    "        return np.concatenate([q_H_mf_u_dot])\n",
    "\n",
    "    def L_mf_q_dot(self, q_mf, q_mf_dot, u_mf):\n",
    "        # q_mf_dot, q_mf (inputs) here will be vectors with ALL of the states\n",
    "        # u_mf is a vector of ALL of the controls\n",
    "        # extract q_s from q_mf\n",
    "        \n",
    "        # note that these methods must return vectors that are of local dimension - state_dim - even though they take in vectors of dimension for all the states\n",
    "        # the user needs to be aware of the indices the correspond to each state\n",
    "\n",
    "        def L_l_q_dot_agent_1(q_mf, q_mf_dot, u_mf):\n",
    "            return np.concatenate([np.array([q_mf[0]]),np.array([q_mf[1]])])\n",
    "        \n",
    "        def L_l_q_dot_agent_2(q_mf, q_mf_dot, u_mf):\n",
    "            return np.concatenate([np.array([q_mf[0]]),np.array([q_mf[1]])])\n",
    "        \n",
    "        L_mf_total_q_dot = np.zeros(self.state_dim)\n",
    "\n",
    "        # agent 1\n",
    "        L_mf_total_q_dot += L_l_q_dot_agent_1(q_mf, q_mf_dot, u_mf)\n",
    "\n",
    "        # agent 2\n",
    "        L_mf_total_q_dot += L_l_q_dot_agent_2(q_mf, q_mf_dot, u_mf)\n",
    "\n",
    "        assert np.shape(L_mf_total_q_dot)[0] == self.state_dim, 'dimensions of L_mf_total_q_dot must match those of the local state, currently the dimensions are ' +str(np.shape(L_mf_total_q_dot)[0])\n",
    "        return L_mf_total_q_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "only 5 should be the resulting set\n"
     ]
    }
   ],
   "source": [
    "a=[3,5,2]\n",
    "b=[2]\n",
    "g=[a,b]\n",
    "set([x for g_i in g for x in g_i]) - set([3,3,3,2,4])\n",
    "print 'only 5 should be the resulting set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Synchronizer:\n",
    "    \n",
    "    def __init__(self, agents, blackboard):\n",
    "        self.agents = agents  # list of all agents. list with elements of class Agent\n",
    "        self.bb = blackboard  # instance of class blackboard\n",
    "        \n",
    "        for agent in agents:\n",
    "            self.bb.update_q_p_u_dict(agent)\n",
    "            \n",
    "        # add Synchronizer as to each agent\n",
    "        for agent in agents:\n",
    "            agent.sync = self\n",
    "    \n",
    "    def synchronize(self):\n",
    "        # run synchronization by visiting each agent and running propagation\n",
    "        for agent in self.agents:\n",
    "            '''     \n",
    "            1) run synchronized propagation - I think we only need one Agent instead of SlidingWindow now\n",
    "\n",
    "            For each of the above 2 steps:\n",
    "                - create sliding window instance\n",
    "                - call \"propagate_dynamics\" on the sliding window instance\n",
    "\n",
    "            get quenched values from blackboard\n",
    "            '''\n",
    "            # run propagation with keyword arguments state_dim_l, state_dim_mf\n",
    "            q_ls_bars, p_ls_bars, p_mfs_bars, u_bars, windows = sliding_window(agent)\n",
    "\n",
    "#     def L_mf_q_dot(self, q_mf, q_mf_dot, u_mf):\n",
    "#         # q_mf_dot, q_mf (inputs) here will be vectors with ALL of the states\n",
    "#         # u_mf is a vector of ALL of the controls\n",
    "#         # extract q_s from q_mf\n",
    "#         L_mf_total_q_dot = 0\n",
    "#         for agent in self.agents:\n",
    "#             # Evaluate L_q_dot for each of the agents\n",
    "#             # Remember L_l_q_dot only takes in the local variables.  So, need to know the indices in q_mf which correspond to \n",
    "#             #...the states pertaining to this agent\n",
    "#             q_s = np.array([q_mf[agent.state_indices[state_ix-1]-1] for state_ix in agent.state_indices])\n",
    "#             q_s_dot = np.array([q_mf_dot[agent.state_indices[state_ix-1]-1] for state_ix in agent.state_indices])\n",
    "#             u_s = np.array([u_mf[agent.control_indices[control_ix-1]-1] for control_ix in agent.control_indices])\n",
    "    \n",
    "#             L_l_q_dot = agent.L_l_q_dot(q_s, q_s_dot, u_s)\n",
    "#             L_mf_total_q_dot = L_mf_total_q_dot + L_l_q_dot\n",
    "            \n",
    "#         return L_mf_total_q_dot\n",
    "\n",
    "    def H_mf(self, q_mf, p_mf, u_mf, agent):\n",
    "        # agent is an object of class agent.  It's the agent for which we are constructing H_mf.\n",
    "        # start with H_mf = H_mf_nou, and then add the H_mf_u's\n",
    "\n",
    "        H_mf = agent.H_mf_nou(q_mf, p_mf, u_mf)\n",
    "        H_mf_u = agent.H_mf_u(q_mf, p_mf, u_mf)\n",
    "        H_mf = H_mf + H_mf_u\n",
    "        \n",
    "        return H_mf\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Blackboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Blackboard:\n",
    "    \n",
    "    def __init__(self):\n",
    "        '''\n",
    "        values: list of integers state_indices state_indices\n",
    "        q_p_u_dict is a dictionary which maps 'q', 'p', 'u', to a dictionary of index-value pairs: local values for q, p, and u for this agent.  \n",
    "                        blackboard holds all of the most recent local values, e.g.\n",
    "                        {'q_s': {'1':3, '2':0}, 'p_mf': {'1':3, '2': 2}, 'u': {'1': 0}}\n",
    "                        It doesn't care which agent updated them most recently.  It only needs to know which values to update.\n",
    "        q_p_u_dict initially will be filled.\n",
    "        '''\n",
    "        ## TODO:  _s should really be called _mf because it contains all of the states/controls.\n",
    "        self.q_p_u_dict = {'q_s':{}, 'p_l':{}, 'p_mf':{}, 'u_s':{}, 'q_s_dot':{}}\n",
    "        self.agents=[]\n",
    "        \n",
    "    def update_q_p_u_dict(self, agent):\n",
    "        '''This method should be called after propagation of each agent\n",
    "        Inputs:\n",
    "            agent (instance of class Agent): this is the agent whose values we are updating\n",
    "        Outputs:\n",
    "            No outputs.  This method just updates the attributes of the blackboard,\n",
    "            just update the dictionary, agent_q_p_u_dict.\n",
    "        '''\n",
    "        # Determine which states pertain to this agent and replace the old values with new\n",
    "        for state_ix in agent.state_indices:\n",
    "            self.q_p_u_dict['q_s'][str(state_ix)] = agent.qpu_vec[:agent.state_dim][state_ix-1]\n",
    "            self.q_p_u_dict['p_l'][str(state_ix)] = agent.qpu_vec[agent.state_dim:2*agent.state_dim][state_ix-1]\n",
    "            self.q_p_u_dict['p_mf'][str(state_ix)] = agent.qpu_vec[2*agent.state_dim:3*agent.state_dim][state_ix-1]\n",
    "            self.q_p_u_dict['q_s_dot'][str(state_ix)] = agent.q_s_dot[state_ix-1]\n",
    "            \n",
    "        for control_ix in agent.control_indices:\n",
    "            self.q_p_u_dict['u_s'][str(control_ix)] = agent.qpu_vec[3*agent.state_dim:][control_ix-1]\n",
    "        \n",
    "        # update sensor values \"q_l, q_l_dot, u_s\"\n",
    "#         self.q_p_u_dict['q_1'] = [] unnecessary because identical to q_s\n",
    "#         self.q_p_u_dict['q_1_dot'] = []  # numerically estimated, or available from sensors\n",
    "#         self.q_p_u_dict['u_s'] = []  # unnecessary because same as \"u_s\" above\n",
    "        \n",
    "        # add agent if not already added \n",
    "        if agent not in self.agents:\n",
    "            self.agents.append(agent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Small test for two agents\n",
    "\n",
    "- Add agents to blackboard and meanfield\n",
    "- Run synchronizer to visit the agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bb = Blackboard()\n",
    "# mean_field = MeanField()\n",
    "\n",
    "myAgent=Agent(bb, state_indices=[1], control_indices=[1])\n",
    "myAgent2=Agent2(bb, state_indices=[1,2], control_indices=[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bb.update_q_p_u_dict(myAgent)\n",
    "bb.update_q_p_u_dict(myAgent2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q_p_u_dict = bb.q_p_u_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'p_l': {'1': 0, '2': 3},\n",
       " 'p_mf': {'1': 0, '2': 1},\n",
       " 'q_s': {'1': 0, '2': 2},\n",
       " 'q_s_dot': {'1': 0, '2': 1},\n",
       " 'u_s': {'1': 0}}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_p_u_dict\n",
    "# this only tells us the values of each state/costate.  Does not tell us which ones correspond to which agent\n",
    "# state_indices attribute of each agent tells us which states pertain to the agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "agents = [myAgent, myAgent2]\n",
    "sync = Synchronizer(agents, bb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try a very small test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Steps to test qp_rhs and u_rhs:\n",
    "\n",
    "- Give some arbitrary initial conditions\n",
    "- create Agent\n",
    "- create Blackboard\n",
    "- create MeanField\n",
    "- connect those three things above.\n",
    "- somehow create a sliding window instance, or at least wrangle the Agent into a Sliding Window instance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# forgot to pass in 'u_s' as a keyword argument\n",
    "qpu_vec, q_ss_bar, p_ls_bar, p_mfs_bar, u_bar, q_ss, p_ls, p_mfs, us, window = propagate_dynamics(myAgent)\n",
    "# forgot to pass in 'u_s' as a keyword argument\n",
    "# qpu_vec2, q_ss_bar2, p_ls_bar2, p_mfs_bar2, u_bar2, q_ss2, p_ls2, p_mfs2, us2 = propagate_dynamics(myAgent2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing plan:\n",
    "    - Test this on a few nonzero inputs\n",
    "    - Test this on multidimensional state\n",
    "    - Test this on multidimensional control\n",
    "    - Get this working for multiple agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.  0.  0. -2.] [0.] [0.] [0.] [-1.] [array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.])] [array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.])] [array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.]), array([0.])] [array([-0.1]), array([-0.2]), array([-0.3]), array([-0.4]), array([-0.5]), array([-0.6]), array([-0.7]), array([-0.8]), array([-0.9]), array([-1.]), array([-1.1]), array([-1.2]), array([-1.3]), array([-1.4]), array([-1.5]), array([-1.6]), array([-1.7]), array([-1.8]), array([-1.9])]\n"
     ]
    }
   ],
   "source": [
    "print qpu_vec, q_ss_bar, p_ls_bar, p_mfs_bar, u_bar, q_ss, p_ls, p_mfs, us\n",
    "\n",
    "# print qpu_vec2, q_ss_bar2, p_ls_bar2, p_mfs_bar2, u_bar2, q_ss2, p_ls2, p_mfs2, us2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Try another very small test\n",
    "\n",
    "- run propagation for Agent using multiple windows so we can test using initial values, etc.\n",
    "- and we can also test all of the methods for the agent rather than only the one for \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get sliding window working for multiple windows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# write helper function to take in sliding window, and q_p_u_dict, and return the q_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('1', 0), ('2', 2)]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q_p_u_dict['q_s'].items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sliding_window(sliding_window_instance):\n",
    "    ''' \n",
    "    This method runs the propagation for a single agent.  Corresponding to the flow chart it runs:\n",
    "        - Read from blackboard to get the following observation measured at time t_0, and onwards\n",
    "        - construct quenched mean field for Hamiltonian agent i\n",
    "        - Setup initial conditions for L_MF and p_MF\n",
    "        - Construct agent synchronized Hamiltonian and partial derivatives\n",
    "    \n",
    "    Inputs:\n",
    "    The only input is sliding_window_instance, but we use the following attributes of the sliding_window_instance:\n",
    "        t_0 (int): Initial time to start propagating dynamics\n",
    "        T (int): End time of propagating dynamics\n",
    "        q_0 (np.array): initial values of state vector\n",
    "        p_0 (np.array): initial values of costate vector\n",
    "        u_0 (np.array): initial values of control vector\n",
    "        state_dim (int): number of states\n",
    "        Gamma (float): algorithmic parameter for Riemann descent algorithm\n",
    "        t_terminal (int): time marking termination of control law propagator algorithm\n",
    "    Outputs:\n",
    "        q_bars, p_bars, u_bars (list of np.arrays): implemented state/costate/control values for entire propagator.\n",
    "    '''\n",
    "    \n",
    "    t_0, T, K, state_dim,t_terminal = sliding_window_instance.t_0, sliding_window_instance.T, sliding_window_instance.K,  sliding_window_instance.state_dim, sliding_window_instance.t_terminal\n",
    "    q_ls_bars, p_ls_bars, p_mfs_bars, u_bars, windows = [], [], [], [], []\n",
    "    t = t_0 # wall clock time\n",
    "    \n",
    "    # Read from blackboard to get the following observations measured at time t_0\n",
    "    q_s_0, q_s_dot_0, u_s_0 = construct_local_vectors(sliding_window_instance)\n",
    "    q_mf, q_mf_dot, u_mf = construct_mf_vectors(sliding_window_instance)\n",
    "\n",
    "    # now pick out the individual states that we need to make q_s and q_s_dot\n",
    "    qpu_vec = sliding_window_instance.qpu_vec\n",
    "    state_dim = sliding_window_instance.state_dim\n",
    "    # a note on q_s_dot - normally I understand that this would come from the sensors, ...\n",
    "    # ...but for now get it from q_mf_dot from the blackboard, and just select if from the states that pertain to this agent\n",
    "    # construct quenched mean field for Hamiltonian agent i\n",
    "    # this happens inside of the class Synchronize method\n",
    "    \n",
    "    # If control is physical, then we should use the physical value here for initial condition\n",
    "    # IF not, then we can use the average u, averaged over the previous window.\n",
    "    # For now, use the value from the blackboard\n",
    "    q_l_D_dot_0 = q_s_dot_0\n",
    "    q_l_D_0 = q_s_0\n",
    "\n",
    "    # set initial conditions using values from blackboard retrieved above\n",
    "    # set initial conditions for local Hamiltonian of agent i\n",
    "    p_l_0 = sliding_window_instance.L_l_q_dot(q_s_0, q_s_dot_0, u_s_0) # compute using Dirac compatibility\n",
    "    p_l_D_0 = sliding_window_instance.L_l_D_q_Dot(q_l_D_0, q_l_D_dot_0) # compute using Dirac compatibility\n",
    "    H_l_D_0 = sliding_window_instance.H_l_D(q_l_D_0, p_l_D_0)\n",
    "    \n",
    "    # setup initial condition for p_mf\n",
    "    p_mf_0 = sliding_window_instance.L_mf_q_dot(q_mf, q_mf_dot, u_mf)\n",
    "    \n",
    "    # now construct qpu_vec \n",
    "    sliding_window_instance.qpu_vec = np.concatenate([q_s_0, p_l_0, p_mf_0, u_s_0]) # fill in with blackboard values for q and u, but for p, must be computed\n",
    "    # Construct local Hamiltonian of agent i\n",
    "    lambdas = sliding_window_instance.compute_lambdas(q_s_0, p_l_0, u_s_0)\n",
    "\n",
    "    while t < sliding_window_instance.t_terminal:\n",
    "        \n",
    "        # for the times, propagate_dynamics needs: t_0, T, and K.  T and K can come from the sliding_window_instance\n",
    "        #...t_0 will be passed in.  t_0 is the start of the window.\n",
    "\n",
    "        # this propagates a single window\n",
    "        # inside of propagate dynamics\n",
    "        qpu_vec, q_ls_bar, p_ls_bar, p_mfs_bar, u_bar, q_ls, p_ls, p_mfs, us, window = propagate_dynamics(sliding_window_instance)\n",
    "        # qs, ps, and us will go to Mean Field somehow\n",
    "        \n",
    "        q_ls_bars.append(q_ls_bar)\n",
    "        p_ls_bars.append(p_ls_bar)\n",
    "        p_mfs_bars.append(p_mfs_bar)\n",
    "        u_bars.append(u_bar)\n",
    "        windows.append(window)\n",
    "\n",
    "        t+=1\n",
    "    # update blackboard\n",
    "    bb.update_q_p_u_dict(sliding_window_instance)\n",
    "    \n",
    "    return q_ls_bars, p_ls_bars, p_mfs_bars, u_bars, windows\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "myAgent.qpu_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "q_ls_bars, p_ls_bars, p_mfs_bars, u_bars, windows = sliding_window(myAgent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ode error: global name 'q_s' is not defined\n",
      "ode error: object of type 'numpy.float64' has no len()\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "too many indices for array",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-42-d70db86759c4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0msync\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msynchronize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-28-a3099474405a>\u001b[0m in \u001b[0;36msynchronize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     25\u001b[0m             '''\n\u001b[1;32m     26\u001b[0m             \u001b[0;31m# run propagation with keyword arguments state_dim_l, state_dim_mf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0mq_ls_bars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_ls_bars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_mfs_bars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_bars\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msliding_window\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;31m#     def L_mf_q_dot(self, q_mf, q_mf_dot, u_mf):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-39-8bafa1d7c10f>\u001b[0m in \u001b[0;36msliding_window\u001b[0;34m(sliding_window_instance)\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;31m# this propagates a single window\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m         \u001b[0;31m# inside of propagate dynamics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m         \u001b[0mqpu_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_ls_bar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_ls_bar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_mfs_bar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_bar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_ls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_ls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp_mfs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mus\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpropagate_dynamics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msliding_window_instance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m         \u001b[0;31m# qs, ps, and us will go to Mean Field somehow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jordan/Documents/Atigeo/cdi/control_law_propagator/sliding_window.py\u001b[0m in \u001b[0;36mpropagate_dynamics\u001b[0;34m(sliding_window_instance)\u001b[0m\n\u001b[1;32m    150\u001b[0m         \u001b[0;31m# retrieve values from blackboard to pass in as kwargs to the rhs functions inside of propagate_q_p and propagate_u\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0mq_mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_mf_dot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconstruct_mf_vectors\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msliding_window_instance\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 152\u001b[0;31m         \u001b[0mqp_vecs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpropagate_q_p\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqpu_vec\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_start\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mt_end\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msliding_window_instance\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mq_mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mu_mf\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# assume \"u\" constant, and propagate q and p\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m         \u001b[0;31m# also need to return derivatives\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/jordan/Documents/Atigeo/cdi/control_law_propagator/sliding_window.py\u001b[0m in \u001b[0;36mpropagate_q_p\u001b[0;34m(qpu_vec, t_start, t_end, sliding_window_instance, q_mf, u_mf)\u001b[0m\n\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m         \u001b[0;31m# rk23 returns 2 arrays but we remove the first array by doing qp_vec[1] because rk_23 returns the initial value you passed in\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m         \u001b[0mqp_vec\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mqp_vec\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0mqp_vecs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mqp_vec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for array"
     ]
    }
   ],
   "source": [
    "sync.synchronize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
